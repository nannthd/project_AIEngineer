{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/AllModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LccyV5ifY15",
        "outputId": "3534129c-0520-4f86-ae73-2d9fbb43180c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVWE6fX_h73C"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KihQv12Rf6ff"
      },
      "source": [
        "#Resnet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5s_H8Y5gJPw"
      },
      "source": [
        "##original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCpfoV25gA1I"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik4mxC9ihEwy",
        "outputId": "eea49914-d5b6-4ba1-f1d0-00d213ec1f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/drug50cls\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/drug50cls.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/drug50cls'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sg2XxmTVopxQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        # เพิ่มภาพที่คล้ายคลึงที่สุดในแต่ละคลาสที่พบ\n",
        "        image_paths = []\n",
        "        for class_name, _ in similar_classes:\n",
        "            class_image_folder = os.path.join(csv_folder_path, class_name)\n",
        "            if os.path.isdir(class_image_folder):\n",
        "                image_files = [f for f in os.listdir(class_image_folder) if f.endswith(('jpg', 'png'))]\n",
        "                if image_files:\n",
        "                    top_image_path = os.path.join(class_image_folder, image_files[0])\n",
        "                    image_paths.append(top_image_path)\n",
        "\n",
        "        # แสดงภาพจากคลาสที่คล้ายคลึงที่สุด\n",
        "        if image_paths:\n",
        "            print(\"Showing similar images:\")\n",
        "            show_images(image_paths, \"Similar Images\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dJfVzwps1mS"
      },
      "source": [
        "ผิด1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_class(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_class = sorted_similarity[0] if sorted_similarity else (None, 0)\n",
        "\n",
        "    return top_class\n",
        "\n",
        "def show_images_with_predictions(image_paths, predictions, title):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, (path, prediction) in enumerate(zip(image_paths, predictions)):\n",
        "        if os.path.isfile(path):  # ตรวจสอบว่าไฟล์มีอยู่จริง\n",
        "            try:\n",
        "                img = Image.open(path)\n",
        "                plt.subplot(3, 4, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis('off')\n",
        "                plt.title(f\"Prediction: {prediction}\", fontsize=8)\n",
        "            except Exception as e:\n",
        "                print(f\"Error opening image {path}: {e}\")\n",
        "        else:\n",
        "            print(f\"File not found: {path}\")\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/test'\n",
        "\n",
        "# เลือกภาพ 12 ภาพแรกจากโฟลเดอร์ทดสอบ\n",
        "all_image_files = [f for f in os.listdir(test_image_folder) if f.endswith(('jpg', 'png'))]\n",
        "first_12_images = all_image_files[:12]\n",
        "\n",
        "# รายการสำหรับเก็บเส้นทางภาพที่คล้ายคลึงและค่าทำนาย\n",
        "all_similar_images = []\n",
        "predictions = []\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดที่เลือก\n",
        "for image_file in first_12_images:\n",
        "    image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "    # ค้นหาคลาสที่มีความคล้ายกันสูงสุด\n",
        "    top_class, similarity_score = find_most_similar_class(image_path, all_embeddings)\n",
        "    prediction = f\"{top_class} ({similarity_score:.2f})\" if top_class else \"Unknown\"\n",
        "\n",
        "    # เพิ่มค่าทำนายและภาพที่คล้ายคลึงสูงสุดจากคลาสที่พบ\n",
        "    predictions.append(prediction)\n",
        "    if top_class:\n",
        "        class_image_folder = os.path.join(csv_folder_path, top_class)\n",
        "        if os.path.isdir(class_image_folder):\n",
        "            image_files = [f for f in os.listdir(class_image_folder) if f.endswith(('jpg', 'png'))]\n",
        "            if image_files:\n",
        "                top_image_path = os.path.join(class_image_folder, image_files[0])\n",
        "                all_similar_images.append(top_image_path)\n",
        "\n",
        "# แสดงภาพทั้งหมดในภาพเดียวกันพร้อมค่าทำนาย\n",
        "print(\"Showing test images and their most similar images with predictions:\")\n",
        "show_images_with_predictions([os.path.join(test_image_folder, img) for img in first_12_images] + all_similar_images, predictions + [''] * len(all_similar_images), \"Test Images and Similar Images\")"
      ],
      "metadata": {
        "id": "S6a2hrL-ICUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ผิด2"
      ],
      "metadata": {
        "id": "YtLUeVXkIw1a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJYoQpg1gCR1"
      },
      "source": [
        "###640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tSfYrh4s802",
        "outputId": "ebf90c0c-b05e-40c4-e745-73acf6a1773b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ไฟล์ถูกแตกที่ /content/drug50cls_640\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/drug50cls_640.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/drug50cls_640'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fLX5VzT9tPON"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        # เพิ่มภาพที่คล้ายคลึงที่สุดในแต่ละคลาสที่พบ\n",
        "        image_paths = []\n",
        "        for class_name, _ in similar_classes:\n",
        "            class_image_folder = os.path.join(csv_folder_path, class_name)\n",
        "            if os.path.isdir(class_image_folder):\n",
        "                image_files = [f for f in os.listdir(class_image_folder) if f.endswith(('jpg', 'png'))]\n",
        "                if image_files:\n",
        "                    top_image_path = os.path.join(class_image_folder, image_files[0])\n",
        "                    image_paths.append(top_image_path)\n",
        "\n",
        "        # แสดงภาพจากคลาสที่คล้ายคลึงที่สุด\n",
        "        if image_paths:\n",
        "            print(\"Showing similar images:\")\n",
        "            show_images(image_paths, \"Similar Images\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siu6HZaZvJA5"
      },
      "source": [
        "ผิด3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Mb2rCMgVaf"
      },
      "source": [
        "##Fine Tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1M2f5tJgYPn"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLwn_q_ovQzy",
        "outputId": "fd951b19-63de-4274-8929-7e5e758a582a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_ResNet50_FT224\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/Vector_ResNet50_FT224.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_ResNet50_FT224'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JKziuNAJLDZh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_224.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    if not os.path.exists(csv_folder):\n",
        "        raise FileNotFoundError(f\"CSV folder {csv_folder} not found.\")\n",
        "\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'ID' in df.columns:\n",
        "                # Drop ID column and keep only class embeddings\n",
        "                embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "                all_embeddings[class_name] = embeddings_no_id\n",
        "            else:\n",
        "                raise ValueError(f\"ID column not found in {csv_file}.\")\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    if not os.path.isdir(new_image_path):\n",
        "        raise FileNotFoundError(f\"Directory {new_image_path} not found.\")\n",
        "\n",
        "    image_files = [os.path.join(new_image_path, f) for f in os.listdir(new_image_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "    results = {}\n",
        "\n",
        "    for image_path in image_files:\n",
        "        new_embedding = image_embedding(image_path)\n",
        "        similarity_scores = {}\n",
        "\n",
        "        for class_name, embeddings_df in all_embeddings.items():\n",
        "            # Compute similarity between new image embedding and class embeddings\n",
        "            similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "            max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "            similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "        sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "        results[image_path] = top_5_similar_classes\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_image_with_results(image_path, similar_classes):\n",
        "    img = Image.open(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Top 5 Similar Classes for {os.path.basename(image_path)}\")\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT224'\n",
        "try:\n",
        "    all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(e)\n",
        "    all_embeddings = {}\n",
        "\n",
        "# Directory containing images to test\n",
        "new_image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "if all_embeddings:\n",
        "    # Find top 5 most similar classes for each image in the folder\n",
        "    try:\n",
        "        similar_classes_results = find_most_similar_classes(new_image_folder_path, all_embeddings)\n",
        "        # Print results and display images\n",
        "        for image_path, similar_classes in similar_classes_results.items():\n",
        "            print(f\"\\nImage: {image_path}\")\n",
        "            print(\"Top 5 most similar classes:\")\n",
        "            for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "                print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "            display_image_with_results(image_path, similar_classes)\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No embeddings loaded, cannot perform similarity search.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxU_YRkgw31T"
      },
      "source": [
        "ผิด2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_224.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    if not os.path.exists(csv_folder):\n",
        "        raise FileNotFoundError(f\"CSV folder {csv_folder} not found.\")\n",
        "\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'ID' in df.columns:\n",
        "                # Drop ID column and keep only class embeddings\n",
        "                embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "                all_embeddings[class_name] = embeddings_no_id\n",
        "            else:\n",
        "                raise ValueError(f\"ID column not found in {csv_file}.\")\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    if not os.path.isdir(new_image_path):\n",
        "        raise FileNotFoundError(f\"Directory {new_image_path} not found.\")\n",
        "\n",
        "    image_files = [os.path.join(new_image_path, f) for f in os.listdir(new_image_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "    # Select the first 12 images\n",
        "    image_files = image_files[:12]\n",
        "    results = {}\n",
        "\n",
        "    for image_path in image_files:\n",
        "        new_embedding = image_embedding(image_path)\n",
        "        similarity_scores = {}\n",
        "\n",
        "        for class_name, embeddings_df in all_embeddings.items():\n",
        "            # Compute similarity between new image embedding and class embeddings\n",
        "            similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "            max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "            similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "        sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_1_similar_class = sorted_similarity[0]  # Get the top 1 similar class\n",
        "\n",
        "        results[image_path] = top_1_similar_class\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_images_grid(images_paths, results, ncols=4):\n",
        "    n_images = len(images_paths)\n",
        "    n_rows = (n_images + ncols - 1) // ncols  # Calculate the number of rows needed\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=n_rows, ncols=ncols, figsize=(ncols * 5, n_rows * 5))\n",
        "    axes = axes.flatten()  # Flatten axes array for easy iteration\n",
        "\n",
        "    for ax, image_path in zip(axes, images_paths):\n",
        "        img = Image.open(image_path)\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        top_class, similarity_score = results[image_path]\n",
        "        ax.set_title(f\"{top_class}\\n{similarity_score:.4f}\")\n",
        "\n",
        "    # Hide any unused axes\n",
        "    for ax in axes[len(images_paths):]:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT224'\n",
        "try:\n",
        "    all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(e)\n",
        "    all_embeddings = {}\n",
        "\n",
        "# Directory containing images to test\n",
        "new_image_folder_path = '/content/drive/MyDrive/drug/test'\n",
        "\n",
        "if all_embeddings:\n",
        "    # Find the most similar class for each image in the folder\n",
        "    try:\n",
        "        similar_classes_results = find_most_similar_classes(new_image_folder_path, all_embeddings)\n",
        "        # Extract image paths and results for display\n",
        "        image_paths = list(similar_classes_results.keys())\n",
        "        results = similar_classes_results\n",
        "        # Display images in a grid\n",
        "        display_images_grid(image_paths, results)\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No embeddings loaded, cannot perform similarity search.\")"
      ],
      "metadata": {
        "id": "qMhJ8nehJEWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ถูกหมด"
      ],
      "metadata": {
        "id": "ffpQbK9BMnqO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyQJnkzogZwp"
      },
      "source": [
        "###640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q2dlmfJw_Y0",
        "outputId": "87d114db-ad1b-4c88-f6c9-8f337d85c4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_ResNet50_FT640\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/Vector_ResNet50_FT640.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_ResNet50_FT640'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OJIJaxZM1gZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_640.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    if not os.path.exists(csv_folder):\n",
        "        raise FileNotFoundError(f\"CSV folder {csv_folder} not found.\")\n",
        "\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'ID' in df.columns:\n",
        "                # Drop ID column and keep only class embeddings\n",
        "                embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "                all_embeddings[class_name] = embeddings_no_id\n",
        "            else:\n",
        "                raise ValueError(f\"ID column not found in {csv_file}.\")\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    if not os.path.isdir(new_image_path):\n",
        "        raise FileNotFoundError(f\"Directory {new_image_path} not found.\")\n",
        "\n",
        "    image_files = [os.path.join(new_image_path, f) for f in os.listdir(new_image_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "    results = {}\n",
        "\n",
        "    for image_path in image_files:\n",
        "        new_embedding = image_embedding(image_path)\n",
        "        similarity_scores = {}\n",
        "\n",
        "        for class_name, embeddings_df in all_embeddings.items():\n",
        "            # Compute similarity between new image embedding and class embeddings\n",
        "            similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "            max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "            similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "        sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "        results[image_path] = top_5_similar_classes\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_image_with_results(image_path, similar_classes):\n",
        "    img = Image.open(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Top 5 Similar Classes for {os.path.basename(image_path)}\")\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT640'\n",
        "try:\n",
        "    all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(e)\n",
        "    all_embeddings = {}\n",
        "\n",
        "# Directory containing images to test\n",
        "new_image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "if all_embeddings:\n",
        "    # Find top 5 most similar classes for each image in the folder\n",
        "    try:\n",
        "        similar_classes_results = find_most_similar_classes(new_image_folder_path, all_embeddings)\n",
        "        # Print results and display images\n",
        "        for image_path, similar_classes in similar_classes_results.items():\n",
        "            print(f\"\\nImage: {image_path}\")\n",
        "            print(\"Top 5 most similar classes:\")\n",
        "            for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "                print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "            display_image_with_results(image_path, similar_classes)\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No embeddings loaded, cannot perform similarity search.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yYnkqbozz_8"
      },
      "source": [
        "ผิด6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_640.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    if not os.path.exists(csv_folder):\n",
        "        raise FileNotFoundError(f\"CSV folder {csv_folder} not found.\")\n",
        "\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'ID' in df.columns:\n",
        "                # Drop ID column and keep only class embeddings\n",
        "                embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "                all_embeddings[class_name] = embeddings_no_id\n",
        "            else:\n",
        "                raise ValueError(f\"ID column not found in {csv_file}.\")\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    if not os.path.isdir(new_image_path):\n",
        "        raise FileNotFoundError(f\"Directory {new_image_path} not found.\")\n",
        "\n",
        "    image_files = [os.path.join(new_image_path, f) for f in os.listdir(new_image_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "    # Select the first 12 images\n",
        "    image_files = image_files[:12]\n",
        "    results = {}\n",
        "\n",
        "    for image_path in image_files:\n",
        "        new_embedding = image_embedding(image_path)\n",
        "        similarity_scores = {}\n",
        "\n",
        "        for class_name, embeddings_df in all_embeddings.items():\n",
        "            # Compute similarity between new image embedding and class embeddings\n",
        "            similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "            max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "            similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "        sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_1_similar_class = sorted_similarity[0]  # Get the top 1 similar class\n",
        "\n",
        "        results[image_path] = top_1_similar_class\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_images_grid(images_paths, results, ncols=4):\n",
        "    n_images = len(images_paths)\n",
        "    n_rows = (n_images + ncols - 1) // ncols  # Calculate the number of rows needed\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=n_rows, ncols=ncols, figsize=(ncols * 5, n_rows * 5))\n",
        "    axes = axes.flatten()  # Flatten axes array for easy iteration\n",
        "\n",
        "    for ax, image_path in zip(axes, images_paths):\n",
        "        img = Image.open(image_path)\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        top_class, similarity_score = results[image_path]\n",
        "        ax.set_title(f\"{top_class}\\n{similarity_score:.4f}\")\n",
        "\n",
        "    # Hide any unused axes\n",
        "    for ax in axes[len(images_paths):]:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT640'\n",
        "try:\n",
        "    all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(e)\n",
        "    all_embeddings = {}\n",
        "\n",
        "# Directory containing images to test\n",
        "new_image_folder_path = '/content/drive/MyDrive/drug/test'\n",
        "\n",
        "if all_embeddings:\n",
        "    # Find the most similar class for each image in the folder\n",
        "    try:\n",
        "        similar_classes_results = find_most_similar_classes(new_image_folder_path, all_embeddings)\n",
        "        # Extract image paths and results for display\n",
        "        image_paths = list(similar_classes_results.keys())\n",
        "        results = similar_classes_results\n",
        "        # Display images in a grid\n",
        "        display_images_grid(image_paths, results)\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No embeddings loaded, cannot perform similarity search.\")"
      ],
      "metadata": {
        "id": "UUS4jlvEJeFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ผิด6"
      ],
      "metadata": {
        "id": "QtAg13V1MkPa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpPupTJ1zM_a"
      },
      "source": [
        "#ViTModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lXGnennzW-6"
      },
      "source": [
        "##original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px1Y8WrxzW-8"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JA18a6GzlBU",
        "outputId": "eb57b33b-ac0b-4ea0-8460-2d860ffae656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ไฟล์ถูกแตกที่ /content/drug50cls_ViTModel\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/drug50cls_ViTModel.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/drug50cls_ViTModel'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR7i3wU02kxk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def process_images_in_folder(image_folder_path, all_embeddings):\n",
        "    results = {}\n",
        "    for image_file in os.listdir(image_folder_path):\n",
        "        image_path = os.path.join(image_folder_path, image_file)\n",
        "        if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            print(f\"Processing image: {image_file}\")\n",
        "            similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "            results[image_file] = (image_path, similar_classes)\n",
        "    return results\n",
        "\n",
        "def display_images_with_results(results):\n",
        "    for image_file, (image_path, similar_classes) in results.items():\n",
        "        img = Image.open(image_path)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 1, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image: {image_file}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        print(f\"\\nImage: {image_file}\")\n",
        "        print(\"Top 5 most similar classes:\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViTModel'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บรูปภาพที่ต้องการทดสอบ\n",
        "image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุดสำหรับแต่ละภาพในโฟลเดอร์\n",
        "results = process_images_in_folder(image_folder_path, all_embeddings)\n",
        "\n",
        "# แสดงภาพพร้อมกับผลลัพธ์\n",
        "display_images_with_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZr15pdGuXfB"
      },
      "source": [
        "ผิด3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpNs8BmnzYYr"
      },
      "source": [
        "###640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPjbq-ur6Qb7",
        "outputId": "0c159734-d0f3-484d-b794-c5201fe46325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ไฟล์ถูกแตกที่ /content/drug50cls_ViTModel_640\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/drug50cls_ViTModel_640.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/drug50cls_ViTModel_640'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W365-GbS6Qb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def process_images_in_folder(image_folder_path, all_embeddings):\n",
        "    results = {}\n",
        "    for image_file in os.listdir(image_folder_path):\n",
        "        image_path = os.path.join(image_folder_path, image_file)\n",
        "        if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            print(f\"Processing image: {image_file}\")\n",
        "            similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "            results[image_file] = (image_path, similar_classes)\n",
        "    return results\n",
        "\n",
        "def display_images_with_results(results):\n",
        "    for image_file, (image_path, similar_classes) in results.items():\n",
        "        img = Image.open(image_path)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 1, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image: {image_file}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        print(f\"\\nImage: {image_file}\")\n",
        "        print(\"Top 5 most similar classes:\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViTModel_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บรูปภาพที่ต้องการทดสอบ\n",
        "image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุดสำหรับแต่ละภาพในโฟลเดอร์\n",
        "results = process_images_in_folder(image_folder_path, all_embeddings)\n",
        "\n",
        "# แสดงภาพพร้อมกับผลลัพธ์\n",
        "display_images_with_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrHhjkBGua2o"
      },
      "source": [
        "ผิด4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCJxs5NvzdMo"
      },
      "source": [
        "##Fine Tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xmvbHT7zdMo"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXngywBO8l79",
        "outputId": "e9b45063-af8f-429a-9331-5fd870c80ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ไฟล์ถูกแตกที่ /content/drug50cls_ViT-FT-model-v1\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/drug50cls_ViT-FT-model-v1.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/drug50cls_ViT-FT-model-v1'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQJOsYb5wiWX"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/drug/ViT_FT_model_v1.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFOMZG-yuoYy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('/content/ViT_FT_model_v1/ViT_FT_model_v1')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes_in_folder(folder_path, all_embeddings):\n",
        "    similarity_results = {}\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(folder_path, image_file)\n",
        "            new_embedding = image_embedding(image_path)\n",
        "            similarity_scores = {}\n",
        "\n",
        "            for class_name, embeddings_df in all_embeddings.items():\n",
        "                similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "                max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "                similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "            sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "            similarity_results[image_path] = top_5_similar_classes\n",
        "\n",
        "    return similarity_results\n",
        "\n",
        "def display_images_with_classes(similarity_results):\n",
        "    for image_path, similar_classes in similarity_results.items():\n",
        "        img = Image.open(image_path)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image: {os.path.basename(image_path)}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Top 5 most similar classes for {os.path.basename(image_path)}:\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "        print()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViT-FT-model-v1'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่มีภาพที่ต้องการทดสอบ\n",
        "folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับสำหรับภาพในโฟลเดอร์\n",
        "similarity_results = find_most_similar_classes_in_folder(folder_path, all_embeddings)\n",
        "\n",
        "# แสดงภาพและผลลัพธ์\n",
        "display_images_with_classes(similarity_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ffu7EJZzejS"
      },
      "source": [
        "###640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqvz_ojnyQrc",
        "outputId": "7eebbc20-2c6a-42f8-a9ba-8417c142438e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/drug50cls_ViT-FT-model-v1_640\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/drug50cls_ViT-FT-model-v1_640.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/drug50cls_ViT-FT-model-v1_640'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/drug/ViT_FT_model_v1.zip'"
      ],
      "metadata": {
        "id": "2VCFu6GRF78y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLsAypjZy-4p",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('/content/ViT_FT_model_v1')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes_in_folder(folder_path, all_embeddings):\n",
        "    similarity_results = {}\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(folder_path, image_file)\n",
        "            new_embedding = image_embedding(image_path)\n",
        "            similarity_scores = {}\n",
        "\n",
        "            for class_name, embeddings_df in all_embeddings.items():\n",
        "                similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "                max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "                similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "            sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "            similarity_results[image_path] = top_5_similar_classes\n",
        "\n",
        "    return similarity_results\n",
        "\n",
        "def display_images_with_classes(similarity_results):\n",
        "    for image_path, similar_classes in similarity_results.items():\n",
        "        img = Image.open(image_path)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image: {os.path.basename(image_path)}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Top 5 most similar classes for {os.path.basename(image_path)}:\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "        print()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViT-FT-model-v1_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่มีภาพที่ต้องการทดสอบ\n",
        "folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับสำหรับภาพในโฟลเดอร์\n",
        "similarity_results = find_most_similar_classes_in_folder(folder_path, all_embeddings)\n",
        "\n",
        "# แสดงภาพและผลลัพธ์\n",
        "display_images_with_classes(similarity_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ถูกหมด"
      ],
      "metadata": {
        "id": "esFUxlo2KBVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('/content/ViT_FT_model_v1')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_class(image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_class = sorted_similarity[0] if sorted_similarity else (None, 0)\n",
        "\n",
        "    return top_class\n",
        "\n",
        "def display_images_with_predictions(images_and_predictions, title):\n",
        "    num_images = len(images_and_predictions)\n",
        "    cols = 4\n",
        "    rows = (num_images + cols - 1) // cols  # คำนวณจำนวนแถวที่ต้องการ\n",
        "    plt.figure(figsize=(15, rows * 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "\n",
        "    for i, (image_path, prediction) in enumerate(images_and_predictions):\n",
        "        img = Image.open(image_path)\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Prediction: {prediction}\", fontsize=8)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViT-FT-model-v1_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่มีภาพที่ต้องการทดสอบ\n",
        "folder_path = '/content/drive/MyDrive/drug/test'\n",
        "\n",
        "# เลือกภาพ 12 ภาพแรกจากโฟลเดอร์ทดสอบ\n",
        "all_image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "first_12_images = all_image_files[:12]  # ใช้ 12 ภาพแรก\n",
        "\n",
        "# รายการสำหรับเก็บเส้นทางภาพและค่าทำนาย\n",
        "images_and_predictions = []\n",
        "\n",
        "for image_file in first_12_images:\n",
        "    image_path = os.path.join(folder_path, image_file)\n",
        "\n",
        "    # ค้นหาคลาสที่มีความคล้ายกันสูงสุด\n",
        "    top_class, similarity_score = find_most_similar_class(image_path, all_embeddings)\n",
        "    prediction = f\"{top_class} ({similarity_score:.2f})\" if top_class else \"Unknown\"\n",
        "\n",
        "    images_and_predictions.append((image_path, prediction))\n",
        "\n",
        "# แสดงภาพทั้งหมดในภาพเดียวกันพร้อมค่าทำนาย\n",
        "print(\"Showing test images with predictions:\")\n",
        "display_images_with_predictions(images_and_predictions, \"Test Images with Predictions\")"
      ],
      "metadata": {
        "id": "7U7apxByKA8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO1MP30y1FQS"
      },
      "source": [
        "#CLIPModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zZCtXuo1Rkw"
      },
      "source": [
        "##original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8rRGdPk1RlM"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKe53h821zUV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Load the CSV file containing the vectors\n",
        "csv_file_path = '/content/drive/MyDrive/drug/class_vectors3.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract the text labels and embeddings from the CSV\n",
        "text_labels = df['TextLabel'].tolist()\n",
        "image_paths = df['ImagePath'].tolist()\n",
        "image_embeddings = df[[col for col in df.columns if 'ImageEmbed_' in col]].values\n",
        "text_embeddings = df[[col for col in df.columns if 'TextEmbed_' in col]].values\n",
        "\n",
        "# Convert embeddings from lists to numpy arrays\n",
        "image_embeddings = np.array(image_embeddings)\n",
        "text_embeddings = np.array(text_embeddings)\n",
        "\n",
        "# Function to compare a new image with stored vectors\n",
        "def compare_image_with_stored_vectors(new_image_path):\n",
        "    # Open the new image\n",
        "    image = Image.open(new_image_path)\n",
        "\n",
        "    # Prepare the inputs for the CLIP model\n",
        "    inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Forward pass through the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the image embedding for the new image\n",
        "    new_image_embedding = outputs.image_embeds.squeeze().cpu().numpy().reshape(1, -1)  # Ensure 2D array\n",
        "\n",
        "    # Get the text embeddings for the new image\n",
        "    new_text_embeddings = outputs.text_embeds.squeeze().cpu().numpy()  # Ensure 2D array\n",
        "\n",
        "    # Print shapes of the new embeddings\n",
        "    print(f\"New image embedding shape: {new_image_embedding.shape}\")\n",
        "    print(f\"New text embeddings shape: {new_text_embeddings.shape}\")\n",
        "\n",
        "    # Ensure dimensions match for cosine similarity\n",
        "    if new_image_embedding.shape[1] != image_embeddings.shape[1]:\n",
        "        raise ValueError(\"Dimension mismatch between new image embedding and stored image embeddings.\")\n",
        "    if new_text_embeddings.shape[1] != text_embeddings.shape[1]:\n",
        "        raise ValueError(\"Dimension mismatch between new text embedding and stored text embeddings.\")\n",
        "\n",
        "    # Compute cosine similarity between new image embedding and stored image embeddings\n",
        "    image_similarities = cosine_similarity(new_image_embedding, image_embeddings)\n",
        "\n",
        "    # Compute cosine similarity between new text embedding and stored text embeddings\n",
        "    text_similarities = cosine_similarity(new_text_embeddings, text_embeddings)\n",
        "\n",
        "    # Combine results from both similarities\n",
        "    combined_similarities = np.maximum(image_similarities, text_similarities)\n",
        "\n",
        "    # Get indices based on combined similarities\n",
        "    most_similar_combined_indices = np.argsort(-combined_similarities, axis=1)[0]\n",
        "\n",
        "    # Get unique classes\n",
        "    unique_classes = set()\n",
        "    top_results = []\n",
        "\n",
        "    # Collect top results avoiding duplicate class names\n",
        "    for index in most_similar_combined_indices:\n",
        "        label = text_labels[index]\n",
        "        if label not in unique_classes:\n",
        "            unique_classes.add(label)\n",
        "            top_results.append((label, combined_similarities[0][index]))  # Fix index usage\n",
        "\n",
        "        if len(top_results) >= 6:  # Collect more than 5 results to ensure we have enough\n",
        "            break\n",
        "\n",
        "    # Print the results from 2nd to 6th most similar\n",
        "    if len(top_results) >= 6:\n",
        "        print(\"\\nRankings from 1st to 5th most similar classes:\")\n",
        "        for i in range(1, 6):  # Indices 1 to 5 are ranks 2 to 6\n",
        "            label, similarity = top_results[i]\n",
        "            print(f\"{label}: {similarity:.4f}\")\n",
        "    elif len(top_results) > 1:\n",
        "        print(\"\\nRankings from 1st to last available:\")\n",
        "        for i in range(1, len(top_results)):  # Indices 1 to end are ranks 2 to last available\n",
        "            label, similarity = top_results[i]\n",
        "            print(f\"{label}: {similarity:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nNot enough results to show rankings from 1st to 5th.\")\n",
        "\n",
        "    # Display the new image\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"New Image: {new_image_path}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Process all images in the base folder\n",
        "base_folder = '/content/drive/MyDrive/drug/CorpTest'  # Base folder containing images\n",
        "\n",
        "for image_file in os.listdir(base_folder):\n",
        "    image_path = os.path.join(base_folder, image_file)\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
        "        print(f\"\\nProcessing image: {image_path}\")\n",
        "        compare_image_with_stored_vectors(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ผิด10"
      ],
      "metadata": {
        "id": "vqysgRQi7QXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#accuracy"
      ],
      "metadata": {
        "id": "RLD5MJ689bcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# จำนวนการทายที่ถูกต้องและจำนวนการทายทั้งหมดสำหรับแต่ละชุด\n",
        "correct_predictions = [49, 47, 49, 45, 47, 46, 49, 50, 40]  # ตัวอย่างค่า\n",
        "total_predictions = [50, 50, 50, 50, 50, 50, 50, 50, 50]    # จำนวนการทายทั้งหมด (ค่าเท่ากันทุกชุด)\n",
        "\n",
        "# คำนวณความแม่นยำสำหรับแต่ละชุด\n",
        "accuracies = [(correct / total) * 100 for correct, total in zip(correct_predictions, total_predictions)]\n",
        "\n",
        "# แสดงผลลัพธ์\n",
        "for i, accuracy in enumerate(accuracies):\n",
        "    print(f\"Accuracy for set {i+1}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHBM-Dct9eJd",
        "outputId": "dee8b843-90e6-4b66-f8cc-c936eff7b8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for set 1: 98.00%\n",
            "Accuracy for set 2: 94.00%\n",
            "Accuracy for set 3: 98.00%\n",
            "Accuracy for set 4: 90.00%\n",
            "Accuracy for set 5: 94.00%\n",
            "Accuracy for set 6: 92.00%\n",
            "Accuracy for set 7: 98.00%\n",
            "Accuracy for set 8: 100.00%\n",
            "Accuracy for set 9: 80.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c5s_H8Y5gJPw",
        "S2Mb2rCMgVaf",
        "2lXGnennzW-6"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}