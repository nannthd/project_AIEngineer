{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/AllModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LccyV5ifY15",
        "outputId": "972b3d55-e81c-4603-e5de-ee0a982999cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVWE6fX_h73C"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KihQv12Rf6ff"
      },
      "source": [
        "#Resnet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5s_H8Y5gJPw"
      },
      "source": [
        "##original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCpfoV25gA1I"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik4mxC9ihEwy",
        "outputId": "80239f2b-16fd-41ac-9508-48626648523f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_Resnet50_224\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/Resnet50/Vector_Resnet50_224.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_Resnet50_224'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sg2XxmTVopxQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_Resnet50_224'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        # เพิ่มภาพที่คล้ายคลึงที่สุดในแต่ละคลาสที่พบ\n",
        "        image_paths = []\n",
        "        for class_name, _ in similar_classes:\n",
        "            class_image_folder = os.path.join(csv_folder_path, class_name)\n",
        "            if os.path.isdir(class_image_folder):\n",
        "                image_files = [f for f in os.listdir(class_image_folder) if f.endswith(('jpg', 'png'))]\n",
        "                if image_files:\n",
        "                    top_image_path = os.path.join(class_image_folder, image_files[0])\n",
        "                    image_paths.append(top_image_path)\n",
        "\n",
        "        # แสดงภาพจากคลาสที่คล้ายคลึงที่สุด\n",
        "        if image_paths:\n",
        "            print(\"Showing similar images:\")\n",
        "            show_images(image_paths, \"Similar Images\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dJfVzwps1mS"
      },
      "source": [
        "ผิด1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "KBCQgrXEVZ0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes, similarity_scores\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_Resnet50_224'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# เก็บข้อมูล similarity ของภาพแต่ละภาพในตัวแปร\n",
        "image_similarity_results = {}\n",
        "\n",
        "# เก็บชื่อคลาสที่แท้จริงจากชื่อไฟล์\n",
        "def get_class_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "true_classes = {}\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        true_class = get_class_from_filename(image_file)\n",
        "        true_classes[image_file] = true_class\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes, similarity_scores = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # เก็บผลลัพธ์ในตัวแปร\n",
        "        image_similarity_results[image_file] = {\n",
        "            'similar_classes': similar_classes,\n",
        "            'similarity_scores': similarity_scores\n",
        "        }\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# สร้างกราฟแสดงผลการทำนาย\n",
        "def plot_prediction_results(image_similarity_results, true_classes):\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        similar_classes = result['similar_classes']\n",
        "        is_correct = [1 if class_name == true_class else 0 for class_name, _ in similar_classes]\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        scores = [score for _, score in similar_classes]\n",
        "\n",
        "        # สร้างกราฟแท่งแสดงการทำนาย\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(labels, scores, color=['green' if correct else 'red' for correct in is_correct])\n",
        "\n",
        "        # เพิ่มข้อความแสดงว่าถูกหรือผิดบนกราฟ\n",
        "        for bar, correct in zip(bars, is_correct):\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, 'ถูก' if correct else 'ผิด', ha='center', fontsize=12)\n",
        "\n",
        "        # กำหนดรายละเอียดกราฟ\n",
        "        plt.title(f'การทำนายสำหรับ {image_file}')\n",
        "        plt.ylabel('คะแนนความมั่นใจ')\n",
        "        plt.ylim(0, 1)  # ตั้งค่าสูงสุดของแกน y เป็น 1\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # แสดงกราฟ\n",
        "        plt.show()\n",
        "\n",
        "# แสดงกราฟผลการทำนาย\n",
        "plot_prediction_results(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "_xV-9UP5NrFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_heatmap(image_similarity_results, true_classes):\n",
        "    all_counts = []\n",
        "    image_files = []\n",
        "    unique_classes = set()\n",
        "\n",
        "    # เก็บชื่อคลาสทั้งหมดที่มี\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        similar_classes = result['similar_classes']\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        unique_classes.update(labels)\n",
        "\n",
        "    unique_classes = sorted(unique_classes)  # เรียงชื่อคลาสตามตัวอักษร\n",
        "\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        # หาคลาสที่มีคะแนนสูงสุด\n",
        "        similar_classes = result['similar_classes']\n",
        "        top_class = similar_classes[0][0]  # คลาสที่มีคะแนนสูงสุด\n",
        "        counts_dict = {class_name: 0 for class_name in unique_classes}\n",
        "        counts_dict[top_class] = 1  # นับจำนวนภาพที่ทำนายคลาสนี้\n",
        "        counts_dict['image_file'] = image_file\n",
        "        all_counts.append(counts_dict)\n",
        "        image_files.append(image_file)\n",
        "\n",
        "    # สร้าง DataFrame และเติมค่า NaN ด้วย 0\n",
        "    counts_df = pd.DataFrame(all_counts).set_index('image_file').fillna(0)\n",
        "    counts_df = counts_df[unique_classes]  # จัดเรียงคอลัมน์ตามชื่อคลาส\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(counts_df, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5, cbar_kws={'label': 'Number of Images'})\n",
        "    plt.title('Heatmap of Top Predicted Classes (Count of Images)')\n",
        "    plt.xlabel('Class Names')\n",
        "    plt.ylabel('Image Files')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดง Heatmap สำหรับจำนวนภาพที่ทำนายคลาสสูงสุด\n",
        "plot_heatmap(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "ul-8CFg2S_pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJYoQpg1gCR1"
      },
      "source": [
        "###640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tSfYrh4s802",
        "outputId": "e1bdee96-7a5b-4e58-c28b-ad15bcc984e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_Resnet50_640\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/Resnet50/Vector_Resnet50_640.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_Resnet50_640'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fLX5VzT9tPON"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_Resnet50_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        # เพิ่มภาพที่คล้ายคลึงที่สุดในแต่ละคลาสที่พบ\n",
        "        image_paths = []\n",
        "        for class_name, _ in similar_classes:\n",
        "            class_image_folder = os.path.join(csv_folder_path, class_name)\n",
        "            if os.path.isdir(class_image_folder):\n",
        "                image_files = [f for f in os.listdir(class_image_folder) if f.endswith(('jpg', 'png'))]\n",
        "                if image_files:\n",
        "                    top_image_path = os.path.join(class_image_folder, image_files[0])\n",
        "                    image_paths.append(top_image_path)\n",
        "\n",
        "        # แสดงภาพจากคลาสที่คล้ายคลึงที่สุด\n",
        "        if image_paths:\n",
        "            print(\"Showing similar images:\")\n",
        "            show_images(image_paths, \"Similar Images\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siu6HZaZvJA5"
      },
      "source": [
        "ผิด3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "lu18kOoQVinD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes, similarity_scores\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_Resnet50_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# เก็บข้อมูล similarity ของภาพแต่ละภาพในตัวแปร\n",
        "image_similarity_results = {}\n",
        "\n",
        "# เก็บชื่อคลาสที่แท้จริงจากชื่อไฟล์\n",
        "def get_class_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "true_classes = {}\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        true_class = get_class_from_filename(image_file)\n",
        "        true_classes[image_file] = true_class\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes, similarity_scores = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # เก็บผลลัพธ์ในตัวแปร\n",
        "        image_similarity_results[image_file] = {\n",
        "            'similar_classes': similar_classes,\n",
        "            'similarity_scores': similarity_scores\n",
        "        }\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# สร้างกราฟแสดงผลการทำนาย\n",
        "def plot_prediction_results(image_similarity_results, true_classes):\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        similar_classes = result['similar_classes']\n",
        "        is_correct = [1 if class_name == true_class else 0 for class_name, _ in similar_classes]\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        scores = [score for _, score in similar_classes]\n",
        "\n",
        "        # สร้างกราฟแท่งแสดงการทำนาย\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(labels, scores, color=['green' if correct else 'red' for correct in is_correct])\n",
        "\n",
        "        # เพิ่มข้อความแสดงว่าถูกหรือผิดบนกราฟ\n",
        "        for bar, correct in zip(bars, is_correct):\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, 'ถูก' if correct else 'ผิด', ha='center', fontsize=12)\n",
        "\n",
        "        # กำหนดรายละเอียดกราฟ\n",
        "        plt.title(f'การทำนายสำหรับ {image_file}')\n",
        "        plt.ylabel('คะแนนความมั่นใจ')\n",
        "        plt.ylim(0, 1)  # ตั้งค่าสูงสุดของแกน y เป็น 1\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # แสดงกราฟ\n",
        "        plt.show()\n",
        "\n",
        "# แสดงกราฟผลการทำนาย\n",
        "plot_prediction_results(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "XuMCQiehVinE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_heatmap(image_similarity_results, true_classes):\n",
        "    all_counts = []\n",
        "    image_files = []\n",
        "    unique_classes = set()\n",
        "\n",
        "    # เก็บชื่อคลาสทั้งหมดที่มี\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        similar_classes = result['similar_classes']\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        unique_classes.update(labels)\n",
        "\n",
        "    unique_classes = sorted(unique_classes)  # เรียงชื่อคลาสตามตัวอักษร\n",
        "\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        # หาคลาสที่มีคะแนนสูงสุด\n",
        "        similar_classes = result['similar_classes']\n",
        "        top_class = similar_classes[0][0]  # คลาสที่มีคะแนนสูงสุด\n",
        "        counts_dict = {class_name: 0 for class_name in unique_classes}\n",
        "        counts_dict[top_class] = 1  # นับจำนวนภาพที่ทำนายคลาสนี้\n",
        "        counts_dict['image_file'] = image_file\n",
        "        all_counts.append(counts_dict)\n",
        "        image_files.append(image_file)\n",
        "\n",
        "    # สร้าง DataFrame และเติมค่า NaN ด้วย 0\n",
        "    counts_df = pd.DataFrame(all_counts).set_index('image_file').fillna(0)\n",
        "    counts_df = counts_df[unique_classes]  # จัดเรียงคอลัมน์ตามชื่อคลาส\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(counts_df, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5, cbar_kws={'label': 'Number of Images'})\n",
        "    plt.title('Heatmap of Top Predicted Classes (Count of Images)')\n",
        "    plt.xlabel('Class Names')\n",
        "    plt.ylabel('Image Files')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดง Heatmap สำหรับจำนวนภาพที่ทำนายคลาสสูงสุด\n",
        "plot_heatmap(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "jSKxercWVinG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Mb2rCMgVaf"
      },
      "source": [
        "##Fine Tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1M2f5tJgYPn"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLwn_q_ovQzy",
        "outputId": "db598ffe-cd26-434b-d3af-4322e8761bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_ResNet50_FT224\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/Resnet50/Vector_ResNet50_FT224.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_ResNet50_FT224'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/Resnet50/model_resnet50_224.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    if not os.path.exists(csv_folder):\n",
        "        raise FileNotFoundError(f\"CSV folder {csv_folder} not found.\")\n",
        "\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'ID' in df.columns:\n",
        "                # Drop ID column and keep only class embeddings\n",
        "                embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "                all_embeddings[class_name] = embeddings_no_id\n",
        "            else:\n",
        "                raise ValueError(f\"ID column not found in {csv_file}.\")\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    if not os.path.isdir(new_image_path):\n",
        "        raise FileNotFoundError(f\"Directory {new_image_path} not found.\")\n",
        "\n",
        "    image_files = [os.path.join(new_image_path, f) for f in os.listdir(new_image_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "    results = {}\n",
        "\n",
        "    for image_path in image_files:\n",
        "        new_embedding = image_embedding(image_path)\n",
        "        similarity_scores = {}\n",
        "\n",
        "        for class_name, embeddings_df in all_embeddings.items():\n",
        "            # Compute similarity between new image embedding and class embeddings\n",
        "            similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "            max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "            similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "        sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "        results[image_path] = top_5_similar_classes\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_image_with_results(image_path, similar_classes):\n",
        "    img = Image.open(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Top 5 Similar Classes for {os.path.basename(image_path)}\")\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT224'\n",
        "try:\n",
        "    all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(e)\n",
        "    all_embeddings = {}\n",
        "\n",
        "# Directory containing images to test\n",
        "new_image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "if all_embeddings:\n",
        "    # Find top 5 most similar classes for each image in the folder\n",
        "    try:\n",
        "        similar_classes_results = find_most_similar_classes(new_image_folder_path, all_embeddings)\n",
        "        # Print results and display images\n",
        "        for image_path, similar_classes in similar_classes_results.items():\n",
        "            print(f\"\\nImage: {image_path}\")\n",
        "            print(\"Top 5 most similar classes:\")\n",
        "            for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "                print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "            display_image_with_results(image_path, similar_classes)\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No embeddings loaded, cannot perform similarity search.\")"
      ],
      "metadata": {
        "id": "y6_eI221aM6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxU_YRkgw31T"
      },
      "source": [
        "ผิด2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "IzL9o13hYIAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the FeatureExtractor class to extract embeddings from the model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        # Use ResNet without the final fully connected layer for feature extraction\n",
        "        self.base_model = nn.Sequential(*list(base_model.children())[:-1])  # Exclude the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.base_model(x)\n",
        "            features = features.view(features.size(0), -1)  # Flatten the features to 1D\n",
        "        return features\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "device = torch.device('cpu')  # Explicitly use CPU\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/Resnet50/model_resnet50_224.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformations and add batch dimension\n",
        "    with torch.no_grad():\n",
        "        embedding = feature_extractor(img)\n",
        "    curr_df = pd.DataFrame(embedding.cpu().numpy())\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV filename as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            # Verify the dimensions\n",
        "            print(f\"Loaded embeddings for class {class_name} with shape: {embeddings_no_id.shape}\")\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # Find the highest similarity score within the class\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes, similarity_scores\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT224'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# Test image folder path\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# Store similarity results\n",
        "image_similarity_results = {}\n",
        "\n",
        "# Get true classes from filenames\n",
        "def get_class_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "true_classes = {}\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        true_class = get_class_from_filename(image_file)\n",
        "        true_classes[image_file] = true_class\n",
        "\n",
        "# Process all images in the folder\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # Find the most similar classes\n",
        "        similar_classes, similarity_scores = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # Store results\n",
        "        image_similarity_results[image_file] = {\n",
        "            'similar_classes': similar_classes,\n",
        "            'similarity_scores': similarity_scores\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # Show test image\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# Plot prediction results\n",
        "def plot_prediction_results(image_similarity_results, true_classes):\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        similar_classes = result['similar_classes']\n",
        "        is_correct = [1 if class_name == true_class else 0 for class_name, _ in similar_classes]\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        scores = [score for _, score in similar_classes]\n",
        "\n",
        "        # Create bar plot for predictions\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(labels, scores, color=['green' if correct else 'red' for correct in is_correct])\n",
        "\n",
        "        # Add text labels for correctness\n",
        "        for bar, correct in zip(bars, is_correct):\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, 'ถูก' if correct else 'ผิด', ha='center', fontsize=12)\n",
        "\n",
        "        # Set plot details\n",
        "        plt.title(f'การทำนายสำหรับ {image_file}')\n",
        "        plt.ylabel('คะแนนความมั่นใจ')\n",
        "        plt.ylim(0, 1)  # Set y-axis limit\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Show plot\n",
        "        plt.show()\n",
        "\n",
        "# Display prediction plots\n",
        "plot_prediction_results(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "6ADK_YCogl1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_heatmap(image_similarity_results, true_classes):\n",
        "    all_counts = []\n",
        "    image_files = []\n",
        "    unique_classes = set()\n",
        "\n",
        "    # เก็บชื่อคลาสทั้งหมดที่มี\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        similar_classes = result['similar_classes']\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        unique_classes.update(labels)\n",
        "\n",
        "    unique_classes = sorted(unique_classes)  # เรียงชื่อคลาสตามตัวอักษร\n",
        "\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        # หาคลาสที่มีคะแนนสูงสุด\n",
        "        similar_classes = result['similar_classes']\n",
        "        top_class = similar_classes[0][0]  # คลาสที่มีคะแนนสูงสุด\n",
        "        counts_dict = {class_name: 0 for class_name in unique_classes}\n",
        "        counts_dict[top_class] = 1  # นับจำนวนภาพที่ทำนายคลาสนี้\n",
        "        counts_dict['image_file'] = image_file\n",
        "        all_counts.append(counts_dict)\n",
        "        image_files.append(image_file)\n",
        "\n",
        "    # สร้าง DataFrame และเติมค่า NaN ด้วย 0\n",
        "    counts_df = pd.DataFrame(all_counts).set_index('image_file').fillna(0)\n",
        "    counts_df = counts_df[unique_classes]  # จัดเรียงคอลัมน์ตามชื่อคลาส\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(counts_df, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5, cbar_kws={'label': 'Number of Images'})\n",
        "    plt.title('Heatmap of Top Predicted Classes (Count of Images)')\n",
        "    plt.xlabel('Class Names')\n",
        "    plt.ylabel('Image Files')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดง Heatmap สำหรับจำนวนภาพที่ทำนายคลาสสูงสุด\n",
        "plot_heatmap(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "JSXXeiFQhVeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyQJnkzogZwp"
      },
      "source": [
        "###640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q2dlmfJw_Y0",
        "outputId": "3c77d7ed-cf45-41e7-e5ce-c8fc04602f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_ResNet50_FT640\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/Resnet50/Vector_ResNet50_FT640.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_ResNet50_FT640'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OJIJaxZM1gZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_640.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    if not os.path.exists(csv_folder):\n",
        "        raise FileNotFoundError(f\"CSV folder {csv_folder} not found.\")\n",
        "\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'ID' in df.columns:\n",
        "                # Drop ID column and keep only class embeddings\n",
        "                embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "                all_embeddings[class_name] = embeddings_no_id\n",
        "            else:\n",
        "                raise ValueError(f\"ID column not found in {csv_file}.\")\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    if not os.path.isdir(new_image_path):\n",
        "        raise FileNotFoundError(f\"Directory {new_image_path} not found.\")\n",
        "\n",
        "    image_files = [os.path.join(new_image_path, f) for f in os.listdir(new_image_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "    results = {}\n",
        "\n",
        "    for image_path in image_files:\n",
        "        new_embedding = image_embedding(image_path)\n",
        "        similarity_scores = {}\n",
        "\n",
        "        for class_name, embeddings_df in all_embeddings.items():\n",
        "            # Compute similarity between new image embedding and class embeddings\n",
        "            similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "            max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "            similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "        sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "        results[image_path] = top_5_similar_classes\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_image_with_results(image_path, similar_classes):\n",
        "    img = Image.open(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Top 5 Similar Classes for {os.path.basename(image_path)}\")\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT640'\n",
        "try:\n",
        "    all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(e)\n",
        "    all_embeddings = {}\n",
        "\n",
        "# Directory containing images to test\n",
        "new_image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "if all_embeddings:\n",
        "    # Find top 5 most similar classes for each image in the folder\n",
        "    try:\n",
        "        similar_classes_results = find_most_similar_classes(new_image_folder_path, all_embeddings)\n",
        "        # Print results and display images\n",
        "        for image_path, similar_classes in similar_classes_results.items():\n",
        "            print(f\"\\nImage: {image_path}\")\n",
        "            print(\"Top 5 most similar classes:\")\n",
        "            for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "                print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "            display_image_with_results(image_path, similar_classes)\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No embeddings loaded, cannot perform similarity search.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yYnkqbozz_8"
      },
      "source": [
        "ผิด6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "nUkywAeEiCjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the FeatureExtractor class to extract embeddings from the model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        # Use ResNet without the final fully connected layer for feature extraction\n",
        "        self.base_model = nn.Sequential(*list(base_model.children())[:-1])  # Exclude the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.base_model(x)\n",
        "            features = features.view(features.size(0), -1)  # Flatten the features to 1D\n",
        "        return features\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "device = torch.device('cpu')  # Explicitly use CPU\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/Resnet50/model_resnet50_640.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformations and add batch dimension\n",
        "    with torch.no_grad():\n",
        "        embedding = feature_extractor(img)\n",
        "    curr_df = pd.DataFrame(embedding.cpu().numpy())\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV filename as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            # Verify the dimensions\n",
        "            print(f\"Loaded embeddings for class {class_name} with shape: {embeddings_no_id.shape}\")\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # Find the highest similarity score within the class\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes, similarity_scores\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/Vector_ResNet50_FT640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# Test image folder path\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# Store similarity results\n",
        "image_similarity_results = {}\n",
        "\n",
        "# Get true classes from filenames\n",
        "def get_class_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "true_classes = {}\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        true_class = get_class_from_filename(image_file)\n",
        "        true_classes[image_file] = true_class\n",
        "\n",
        "# Process all images in the folder\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # Find the most similar classes\n",
        "        similar_classes, similarity_scores = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # Store results\n",
        "        image_similarity_results[image_file] = {\n",
        "            'similar_classes': similar_classes,\n",
        "            'similarity_scores': similarity_scores\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # Show test image\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# Plot prediction results\n",
        "def plot_prediction_results(image_similarity_results, true_classes):\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        similar_classes = result['similar_classes']\n",
        "        is_correct = [1 if class_name == true_class else 0 for class_name, _ in similar_classes]\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        scores = [score for _, score in similar_classes]\n",
        "\n",
        "        # Create bar plot for predictions\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(labels, scores, color=['green' if correct else 'red' for correct in is_correct])\n",
        "\n",
        "        # Add text labels for correctness\n",
        "        for bar, correct in zip(bars, is_correct):\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, 'ถูก' if correct else 'ผิด', ha='center', fontsize=12)\n",
        "\n",
        "        # Set plot details\n",
        "        plt.title(f'การทำนายสำหรับ {image_file}')\n",
        "        plt.ylabel('คะแนนความมั่นใจ')\n",
        "        plt.ylim(0, 1)  # Set y-axis limit\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Show plot\n",
        "        plt.show()\n",
        "\n",
        "# Display prediction plots\n",
        "plot_prediction_results(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "cDx4c4HEiEtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_heatmap(image_similarity_results, true_classes):\n",
        "    all_counts = []\n",
        "    image_files = []\n",
        "    unique_classes = set()\n",
        "\n",
        "    # เก็บชื่อคลาสทั้งหมดที่มี\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        similar_classes = result['similar_classes']\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        unique_classes.update(labels)\n",
        "\n",
        "    unique_classes = sorted(unique_classes)  # เรียงชื่อคลาสตามตัวอักษร\n",
        "\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        # หาคลาสที่มีคะแนนสูงสุด\n",
        "        similar_classes = result['similar_classes']\n",
        "        top_class = similar_classes[0][0]  # คลาสที่มีคะแนนสูงสุด\n",
        "        counts_dict = {class_name: 0 for class_name in unique_classes}\n",
        "        counts_dict[top_class] = 1  # นับจำนวนภาพที่ทำนายคลาสนี้\n",
        "        counts_dict['image_file'] = image_file\n",
        "        all_counts.append(counts_dict)\n",
        "        image_files.append(image_file)\n",
        "\n",
        "    # สร้าง DataFrame และเติมค่า NaN ด้วย 0\n",
        "    counts_df = pd.DataFrame(all_counts).set_index('image_file').fillna(0)\n",
        "    counts_df = counts_df[unique_classes]  # จัดเรียงคอลัมน์ตามชื่อคลาส\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(counts_df, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5, cbar_kws={'label': 'Number of Images'})\n",
        "    plt.title('Heatmap of Top Predicted Classes (Count of Images)')\n",
        "    plt.xlabel('Class Names')\n",
        "    plt.ylabel('Image Files')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดง Heatmap สำหรับจำนวนภาพที่ทำนายคลาสสูงสุด\n",
        "plot_heatmap(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "-7bWJpzyjIMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpPupTJ1zM_a"
      },
      "source": [
        "#ViTModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lXGnennzW-6"
      },
      "source": [
        "##original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px1Y8WrxzW-8"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JA18a6GzlBU",
        "outputId": "fcab6d19-c205-42d4-bb4b-159232a67177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_VITModel_224\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/VITModel/Vector_VITModel_224.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_VITModel_224'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR7i3wU02kxk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def process_images_in_folder(image_folder_path, all_embeddings):\n",
        "    results = {}\n",
        "    for image_file in os.listdir(image_folder_path):\n",
        "        image_path = os.path.join(image_folder_path, image_file)\n",
        "        if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            print(f\"Processing image: {image_file}\")\n",
        "            similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "            results[image_file] = (image_path, similar_classes)\n",
        "    return results\n",
        "\n",
        "def display_images_with_results(results):\n",
        "    for image_file, (image_path, similar_classes) in results.items():\n",
        "        img = Image.open(image_path)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 1, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image: {image_file}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        print(f\"\\nImage: {image_file}\")\n",
        "        print(\"Top 5 most similar classes:\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_VITModel_224'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บรูปภาพที่ต้องการทดสอบ\n",
        "image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุดสำหรับแต่ละภาพในโฟลเดอร์\n",
        "results = process_images_in_folder(image_folder_path, all_embeddings)\n",
        "\n",
        "# แสดงภาพพร้อมกับผลลัพธ์\n",
        "display_images_with_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZr15pdGuXfB"
      },
      "source": [
        "ผิด3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "MSNBoWwM1FQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes, similarity_scores\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_VITModel_224'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# เก็บข้อมูล similarity ของภาพแต่ละภาพในตัวแปร\n",
        "image_similarity_results = {}\n",
        "\n",
        "# เก็บชื่อคลาสที่แท้จริงจากชื่อไฟล์\n",
        "def get_class_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "true_classes = {}\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        true_class = get_class_from_filename(image_file)\n",
        "        true_classes[image_file] = true_class\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes, similarity_scores = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # เก็บผลลัพธ์ในตัวแปร\n",
        "        image_similarity_results[image_file] = {\n",
        "            'similar_classes': similar_classes,\n",
        "            'similarity_scores': similarity_scores\n",
        "        }\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# สร้างกราฟแสดงผลการทำนาย\n",
        "def plot_prediction_results(image_similarity_results, true_classes):\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        similar_classes = result['similar_classes']\n",
        "        is_correct = [1 if class_name == true_class else 0 for class_name, _ in similar_classes]\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        scores = [score for _, score in similar_classes]\n",
        "\n",
        "        # สร้างกราฟแท่งแสดงการทำนาย\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(labels, scores, color=['green' if correct else 'red' for correct in is_correct])\n",
        "\n",
        "        # เพิ่มข้อความแสดงว่าถูกหรือผิดบนกราฟ\n",
        "        for bar, correct in zip(bars, is_correct):\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, 'ถูก' if correct else 'ผิด', ha='center', fontsize=12)\n",
        "\n",
        "        # กำหนดรายละเอียดกราฟ\n",
        "        plt.title(f'การทำนายสำหรับ {image_file}')\n",
        "        plt.ylabel('คะแนนความมั่นใจ')\n",
        "        plt.ylim(0, 1)  # ตั้งค่าสูงสุดของแกน y เป็น 1\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # แสดงกราฟ\n",
        "        plt.show()\n",
        "\n",
        "# แสดงกราฟผลการทำนาย\n",
        "plot_prediction_results(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "VObtDOmYRviv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_heatmap(image_similarity_results, true_classes):\n",
        "    all_counts = []\n",
        "    image_files = []\n",
        "    unique_classes = set()\n",
        "\n",
        "    # เก็บชื่อคลาสทั้งหมดที่มี\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        similar_classes = result['similar_classes']\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        unique_classes.update(labels)\n",
        "\n",
        "    unique_classes = sorted(unique_classes)  # เรียงชื่อคลาสตามตัวอักษร\n",
        "\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        # หาคลาสที่มีคะแนนสูงสุด\n",
        "        similar_classes = result['similar_classes']\n",
        "        top_class = similar_classes[0][0]  # คลาสที่มีคะแนนสูงสุด\n",
        "        counts_dict = {class_name: 0 for class_name in unique_classes}\n",
        "        counts_dict[top_class] = 1  # นับจำนวนภาพที่ทำนายคลาสนี้\n",
        "        counts_dict['image_file'] = image_file\n",
        "        all_counts.append(counts_dict)\n",
        "        image_files.append(image_file)\n",
        "\n",
        "    # สร้าง DataFrame และเติมค่า NaN ด้วย 0\n",
        "    counts_df = pd.DataFrame(all_counts).set_index('image_file').fillna(0)\n",
        "    counts_df = counts_df[unique_classes]  # จัดเรียงคอลัมน์ตามชื่อคลาส\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(counts_df, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5, cbar_kws={'label': 'Number of Images'})\n",
        "    plt.title('Heatmap of Top Predicted Classes (Count of Images)')\n",
        "    plt.xlabel('Class Names')\n",
        "    plt.ylabel('Image Files')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดง Heatmap สำหรับจำนวนภาพที่ทำนายคลาสสูงสุด\n",
        "plot_heatmap(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "J6C4MDepR9IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpNs8BmnzYYr"
      },
      "source": [
        "###640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPjbq-ur6Qb7",
        "outputId": "8028a445-e585-49f9-bab6-75adca858e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_VITModel_640\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/VITModel/Vector_VITModel_640.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_VITModel_640'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W365-GbS6Qb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def process_images_in_folder(image_folder_path, all_embeddings):\n",
        "    results = {}\n",
        "    for image_file in os.listdir(image_folder_path):\n",
        "        image_path = os.path.join(image_folder_path, image_file)\n",
        "        if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            print(f\"Processing image: {image_file}\")\n",
        "            similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "            results[image_file] = (image_path, similar_classes)\n",
        "    return results\n",
        "\n",
        "def display_images_with_results(results):\n",
        "    for image_file, (image_path, similar_classes) in results.items():\n",
        "        img = Image.open(image_path)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 1, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image: {image_file}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        print(f\"\\nImage: {image_file}\")\n",
        "        print(\"Top 5 most similar classes:\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViTModel_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บรูปภาพที่ต้องการทดสอบ\n",
        "image_folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุดสำหรับแต่ละภาพในโฟลเดอร์\n",
        "results = process_images_in_folder(image_folder_path, all_embeddings)\n",
        "\n",
        "# แสดงภาพพร้อมกับผลลัพธ์\n",
        "display_images_with_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrHhjkBGua2o"
      },
      "source": [
        "ผิด4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "b-5rUI_DTA2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes, similarity_scores\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_VITModel_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# เก็บข้อมูล similarity ของภาพแต่ละภาพในตัวแปร\n",
        "image_similarity_results = {}\n",
        "\n",
        "# เก็บชื่อคลาสที่แท้จริงจากชื่อไฟล์\n",
        "def get_class_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "true_classes = {}\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        true_class = get_class_from_filename(image_file)\n",
        "        true_classes[image_file] = true_class\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes, similarity_scores = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # เก็บผลลัพธ์ในตัวแปร\n",
        "        image_similarity_results[image_file] = {\n",
        "            'similar_classes': similar_classes,\n",
        "            'similarity_scores': similarity_scores\n",
        "        }\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# สร้างกราฟแสดงผลการทำนาย\n",
        "def plot_prediction_results(image_similarity_results, true_classes):\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        similar_classes = result['similar_classes']\n",
        "        is_correct = [1 if class_name == true_class else 0 for class_name, _ in similar_classes]\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        scores = [score for _, score in similar_classes]\n",
        "\n",
        "        # สร้างกราฟแท่งแสดงการทำนาย\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(labels, scores, color=['green' if correct else 'red' for correct in is_correct])\n",
        "\n",
        "        # เพิ่มข้อความแสดงว่าถูกหรือผิดบนกราฟ\n",
        "        for bar, correct in zip(bars, is_correct):\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, 'ถูก' if correct else 'ผิด', ha='center', fontsize=12)\n",
        "\n",
        "        # กำหนดรายละเอียดกราฟ\n",
        "        plt.title(f'การทำนายสำหรับ {image_file}')\n",
        "        plt.ylabel('คะแนนความมั่นใจ')\n",
        "        plt.ylim(0, 1)  # ตั้งค่าสูงสุดของแกน y เป็น 1\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # แสดงกราฟ\n",
        "        plt.show()\n",
        "\n",
        "# แสดงกราฟผลการทำนาย\n",
        "plot_prediction_results(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "2QGtr0laTCu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_heatmap(image_similarity_results, true_classes):\n",
        "    all_counts = []\n",
        "    image_files = []\n",
        "    unique_classes = set()\n",
        "\n",
        "    # เก็บชื่อคลาสทั้งหมดที่มี\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        similar_classes = result['similar_classes']\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        unique_classes.update(labels)\n",
        "\n",
        "    unique_classes = sorted(unique_classes)  # เรียงชื่อคลาสตามตัวอักษร\n",
        "\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        # หาคลาสที่มีคะแนนสูงสุด\n",
        "        similar_classes = result['similar_classes']\n",
        "        top_class = similar_classes[0][0]  # คลาสที่มีคะแนนสูงสุด\n",
        "        counts_dict = {class_name: 0 for class_name in unique_classes}\n",
        "        counts_dict[top_class] = 1  # นับจำนวนภาพที่ทำนายคลาสนี้\n",
        "        counts_dict['image_file'] = image_file\n",
        "        all_counts.append(counts_dict)\n",
        "        image_files.append(image_file)\n",
        "\n",
        "    # สร้าง DataFrame และเติมค่า NaN ด้วย 0\n",
        "    counts_df = pd.DataFrame(all_counts).set_index('image_file').fillna(0)\n",
        "    counts_df = counts_df[unique_classes]  # จัดเรียงคอลัมน์ตามชื่อคลาส\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(counts_df, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5, cbar_kws={'label': 'Number of Images'})\n",
        "    plt.title('Heatmap of Top Predicted Classes (Count of Images)')\n",
        "    plt.xlabel('Class Names')\n",
        "    plt.ylabel('Image Files')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดง Heatmap สำหรับจำนวนภาพที่ทำนายคลาสสูงสุด\n",
        "plot_heatmap(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "9-p98R7cTf8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCJxs5NvzdMo"
      },
      "source": [
        "##Fine Tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xmvbHT7zdMo"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/VITModel/model_VITModel_224.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/model_VITModel_224'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5lYwEbJUHI4",
        "outputId": "ec18c251-74ee-4895-a38b-710eb73f53b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/model_VITModel_224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXngywBO8l79",
        "outputId": "347e70bc-f4a7-44c2-af11-e41a015083c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ถูกแตกที่ /content/Vector_VITModel_FT224\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to_folder):\n",
        "    # ตรวจสอบว่ามีโฟลเดอร์ปลายทางหรือไม่ ถ้าไม่มีก็สร้างใหม่\n",
        "    if not os.path.exists(extract_to_folder):\n",
        "        os.makedirs(extract_to_folder)\n",
        "\n",
        "    # เปิดไฟล์ ZIP และแตกไฟล์\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_folder)\n",
        "        print(f'ไฟล์ถูกแตกที่ {extract_to_folder}')\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_path = '/content/drive/MyDrive/drug/FineTune/VITModel/Vector_VITModel_FT224.zip'  # ใส่เส้นทางไฟล์ ZIP ของคุณที่นี่\n",
        "extract_to_folder = '/content/Vector_VITModel_FT224'  # ใส่เส้นทางโฟลเดอร์ที่ต้องการแตกไฟล์ที่นี่\n",
        "unzip_file(zip_path, extract_to_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFOMZG-yuoYy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('/content/ViT_FT_model_v1/ViT_FT_model_v1')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes_in_folder(folder_path, all_embeddings):\n",
        "    similarity_results = {}\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(folder_path, image_file)\n",
        "            new_embedding = image_embedding(image_path)\n",
        "            similarity_scores = {}\n",
        "\n",
        "            for class_name, embeddings_df in all_embeddings.items():\n",
        "                similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "                max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "                similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "            sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "            similarity_results[image_path] = top_5_similar_classes\n",
        "\n",
        "    return similarity_results\n",
        "\n",
        "def display_images_with_classes(similarity_results):\n",
        "    for image_path, similar_classes in similarity_results.items():\n",
        "        img = Image.open(image_path)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image: {os.path.basename(image_path)}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Top 5 most similar classes for {os.path.basename(image_path)}:\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "        print()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViT-FT-model-v1'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่มีภาพที่ต้องการทดสอบ\n",
        "folder_path = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับสำหรับภาพในโฟลเดอร์\n",
        "similarity_results = find_most_similar_classes_in_folder(folder_path, all_embeddings)\n",
        "\n",
        "# แสดงภาพและผลลัพธ์\n",
        "display_images_with_classes(similarity_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "HLe15P4nU3NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('/content/model_VITModel_224')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes, similarity_scores\n",
        "\n",
        "def show_images(image_paths, title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    for i, path in enumerate(image_paths):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_VITModel_FT224'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่เก็บภาพที่จะทดสอบ\n",
        "test_image_folder = '/content/drive/MyDrive/drug/CorpTest'\n",
        "\n",
        "# เก็บข้อมูล similarity ของภาพแต่ละภาพในตัวแปร\n",
        "image_similarity_results = {}\n",
        "\n",
        "# เก็บชื่อคลาสที่แท้จริงจากชื่อไฟล์\n",
        "def get_class_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "true_classes = {}\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        true_class = get_class_from_filename(image_file)\n",
        "        true_classes[image_file] = true_class\n",
        "\n",
        "# ประมวลผลภาพทั้งหมดในโฟลเดอร์\n",
        "for image_file in os.listdir(test_image_folder):\n",
        "    if image_file.endswith(('jpg', 'png')):\n",
        "        image_path = os.path.join(test_image_folder, image_file)\n",
        "\n",
        "        # ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "        similar_classes, similarity_scores = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "        # เก็บผลลัพธ์ในตัวแปร\n",
        "        image_similarity_results[image_file] = {\n",
        "            'similar_classes': similar_classes,\n",
        "            'similarity_scores': similarity_scores\n",
        "        }\n",
        "\n",
        "        # แสดงผลลัพธ์\n",
        "        print(f\"Results for image: {image_file}\")\n",
        "        for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "            print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "        # แสดงภาพทดสอบ\n",
        "        print(\"Showing test image:\")\n",
        "        show_images([image_path], \"Test Image\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# สร้างกราฟแสดงผลการทำนาย\n",
        "def plot_prediction_results(image_similarity_results, true_classes):\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        similar_classes = result['similar_classes']\n",
        "        is_correct = [1 if class_name == true_class else 0 for class_name, _ in similar_classes]\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        scores = [score for _, score in similar_classes]\n",
        "\n",
        "        # สร้างกราฟแท่งแสดงการทำนาย\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(labels, scores, color=['green' if correct else 'red' for correct in is_correct])\n",
        "\n",
        "        # เพิ่มข้อความแสดงว่าถูกหรือผิดบนกราฟ\n",
        "        for bar, correct in zip(bars, is_correct):\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, 'ถูก' if correct else 'ผิด', ha='center', fontsize=12)\n",
        "\n",
        "        # กำหนดรายละเอียดกราฟ\n",
        "        plt.title(f'การทำนายสำหรับ {image_file}')\n",
        "        plt.ylabel('คะแนนความมั่นใจ')\n",
        "        plt.ylim(0, 1)  # ตั้งค่าสูงสุดของแกน y เป็น 1\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # แสดงกราฟ\n",
        "        plt.show()\n",
        "\n",
        "# แสดงกราฟผลการทำนาย\n",
        "plot_prediction_results(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "0nQpeVpjU4BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_heatmap(image_similarity_results, true_classes):\n",
        "    all_counts = []\n",
        "    image_files = []\n",
        "    unique_classes = set()\n",
        "\n",
        "    # เก็บชื่อคลาสทั้งหมดที่มี\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        similar_classes = result['similar_classes']\n",
        "        labels = [class_name for class_name, _ in similar_classes]\n",
        "        unique_classes.update(labels)\n",
        "\n",
        "    unique_classes = sorted(unique_classes)  # เรียงชื่อคลาสตามตัวอักษร\n",
        "\n",
        "    for image_file, result in image_similarity_results.items():\n",
        "        true_class = true_classes.get(image_file, None)\n",
        "        if not true_class:\n",
        "            continue\n",
        "\n",
        "        # หาคลาสที่มีคะแนนสูงสุด\n",
        "        similar_classes = result['similar_classes']\n",
        "        top_class = similar_classes[0][0]  # คลาสที่มีคะแนนสูงสุด\n",
        "        counts_dict = {class_name: 0 for class_name in unique_classes}\n",
        "        counts_dict[top_class] = 1  # นับจำนวนภาพที่ทำนายคลาสนี้\n",
        "        counts_dict['image_file'] = image_file\n",
        "        all_counts.append(counts_dict)\n",
        "        image_files.append(image_file)\n",
        "\n",
        "    # สร้าง DataFrame และเติมค่า NaN ด้วย 0\n",
        "    counts_df = pd.DataFrame(all_counts).set_index('image_file').fillna(0)\n",
        "    counts_df = counts_df[unique_classes]  # จัดเรียงคอลัมน์ตามชื่อคลาส\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(counts_df, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5, cbar_kws={'label': 'Number of Images'})\n",
        "    plt.title('Heatmap of Top Predicted Classes (Count of Images)')\n",
        "    plt.xlabel('Class Names')\n",
        "    plt.ylabel('Image Files')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดง Heatmap สำหรับจำนวนภาพที่ทำนายคลาสสูงสุด\n",
        "plot_heatmap(image_similarity_results, true_classes)"
      ],
      "metadata": {
        "id": "wPnm9pk6VSys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO1MP30y1FQS"
      },
      "source": [
        "#CLIPModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zZCtXuo1Rkw"
      },
      "source": [
        "##original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8rRGdPk1RlM"
      },
      "source": [
        "###224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKe53h821zUV",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Load the CSV file containing the vectors\n",
        "csv_file_path = '/content/drive/MyDrive/drug/FineTune/CLIPModel/class_vectors.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract the text labels and embeddings from the CSV\n",
        "text_labels = df['TextLabel'].tolist()\n",
        "image_paths = df['ImagePath'].tolist()\n",
        "image_embeddings = df[[col for col in df.columns if 'ImageEmbed_' in col]].values\n",
        "text_embeddings = df[[col for col in df.columns if 'TextEmbed_' in col]].values\n",
        "\n",
        "# Convert embeddings from lists to numpy arrays\n",
        "image_embeddings = np.array(image_embeddings)\n",
        "text_embeddings = np.array(text_embeddings)\n",
        "\n",
        "# Function to compare a new image with stored vectors\n",
        "def compare_image_with_stored_vectors(new_image_path):\n",
        "    # Open the new image\n",
        "    image = Image.open(new_image_path)\n",
        "\n",
        "    # Prepare the inputs for the CLIP model\n",
        "    inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Forward pass through the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the image embedding for the new image\n",
        "    new_image_embedding = outputs.image_embeds.squeeze().cpu().numpy().reshape(1, -1)  # Ensure 2D array\n",
        "\n",
        "    # Get the text embeddings for the new image\n",
        "    new_text_embeddings = outputs.text_embeds.squeeze().cpu().numpy()  # Ensure 2D array\n",
        "\n",
        "    # Print shapes of the new embeddings\n",
        "    print(f\"New image embedding shape: {new_image_embedding.shape}\")\n",
        "    print(f\"New text embeddings shape: {new_text_embeddings.shape}\")\n",
        "\n",
        "    # Ensure dimensions match for cosine similarity\n",
        "    if new_image_embedding.shape[1] != image_embeddings.shape[1]:\n",
        "        raise ValueError(\"Dimension mismatch between new image embedding and stored image embeddings.\")\n",
        "    if new_text_embeddings.shape[1] != text_embeddings.shape[1]:\n",
        "        raise ValueError(\"Dimension mismatch between new text embedding and stored text embeddings.\")\n",
        "\n",
        "    # Compute cosine similarity between new image embedding and stored image embeddings\n",
        "    image_similarities = cosine_similarity(new_image_embedding, image_embeddings)\n",
        "\n",
        "    # Compute cosine similarity between new text embedding and stored text embeddings\n",
        "    text_similarities = cosine_similarity(new_text_embeddings, text_embeddings)\n",
        "\n",
        "    # Combine results from both similarities\n",
        "    combined_similarities = np.maximum(image_similarities, text_similarities)\n",
        "\n",
        "    # Get indices based on combined similarities\n",
        "    most_similar_combined_indices = np.argsort(-combined_similarities, axis=1)[0]\n",
        "\n",
        "    # Get unique classes\n",
        "    unique_classes = set()\n",
        "    top_results = []\n",
        "\n",
        "    # Collect top results avoiding duplicate class names\n",
        "    for index in most_similar_combined_indices:\n",
        "        label = text_labels[index]\n",
        "        if label not in unique_classes:\n",
        "            unique_classes.add(label)\n",
        "            top_results.append((label, combined_similarities[0][index]))  # Fix index usage\n",
        "\n",
        "        if len(top_results) >= 6:  # Collect more than 5 results to ensure we have enough\n",
        "            break\n",
        "\n",
        "    # Print the results from 2nd to 6th most similar\n",
        "    if len(top_results) >= 6:\n",
        "        print(\"\\nRankings from 1st to 5th most similar classes:\")\n",
        "        for i in range(1, 6):  # Indices 1 to 5 are ranks 2 to 6\n",
        "            label, similarity = top_results[i]\n",
        "            print(f\"{label}: {similarity:.4f}\")\n",
        "    elif len(top_results) > 1:\n",
        "        print(\"\\nRankings from 1st to last available:\")\n",
        "        for i in range(1, len(top_results)):  # Indices 1 to end are ranks 2 to last available\n",
        "            label, similarity = top_results[i]\n",
        "            print(f\"{label}: {similarity:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nNot enough results to show rankings from 1st to 5th.\")\n",
        "\n",
        "    # Display the new image\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"New Image: {new_image_path}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Process all images in the base folder\n",
        "base_folder = '/content/drive/MyDrive/drug/CorpTest'  # Base folder containing images\n",
        "\n",
        "for image_file in os.listdir(base_folder):\n",
        "    image_path = os.path.join(base_folder, image_file)\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
        "        print(f\"\\nProcessing image: {image_path}\")\n",
        "        compare_image_with_stored_vectors(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ผิด10"
      ],
      "metadata": {
        "id": "vqysgRQi7QXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ใหม่"
      ],
      "metadata": {
        "id": "7yUzeqR0bfUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#accuracy"
      ],
      "metadata": {
        "id": "RLD5MJ689bcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# จำนวนการทายที่ถูกต้องและจำนวนการทายทั้งหมดสำหรับแต่ละชุด\n",
        "correct_predictions = [49, 47, 49, 45, 47, 46, 49, 50, 40]  # ตัวอย่างค่า\n",
        "total_predictions = [50, 50, 50, 50, 50, 50, 50, 50, 50]    # จำนวนการทายทั้งหมด (ค่าเท่ากันทุกชุด)\n",
        "\n",
        "# คำนวณความแม่นยำสำหรับแต่ละชุด\n",
        "accuracies = [(correct / total) * 100 for correct, total in zip(correct_predictions, total_predictions)]\n",
        "\n",
        "# แสดงผลลัพธ์\n",
        "for i, accuracy in enumerate(accuracies):\n",
        "    print(f\"Accuracy for set {i+1}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHBM-Dct9eJd",
        "outputId": "dee8b843-90e6-4b66-f8cc-c936eff7b8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for set 1: 98.00%\n",
            "Accuracy for set 2: 94.00%\n",
            "Accuracy for set 3: 98.00%\n",
            "Accuracy for set 4: 90.00%\n",
            "Accuracy for set 5: 94.00%\n",
            "Accuracy for set 6: 92.00%\n",
            "Accuracy for set 7: 98.00%\n",
            "Accuracy for set 8: 100.00%\n",
            "Accuracy for set 9: 80.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c5s_H8Y5gJPw",
        "S2Mb2rCMgVaf",
        "2lXGnennzW-6"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}