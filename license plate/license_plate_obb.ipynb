{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/nannthd/project_AIEngineer/blob/main/license_plate_EasyOCR2.ipynb",
      "authorship_tag": "ABX9TyOBK3kXEJ5oNqgqJMjQVwLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/license_plate_obb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ij01tPP-NWj",
        "outputId": "09a95489-6240-46a7-e3c4-b93083915db0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G-yvS2iAd9N"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GJM44AFTvvnN"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"AWtZRbYK04sFZNNZ1t4X\")\n",
        "project = rf.workspace(\"projectaiengineer\").project(\"license-plates-gpj5f\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8-obb\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open(f'{dataset.location}/data.yaml', 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "data['path'] = dataset.location\n",
        "\n",
        "with open(f'{dataset.location}/data.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, sort_keys=False)"
      ],
      "metadata": {
        "id": "A5ZJ1vuMvDUF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "8ppGykFHpSbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "fYXp1wOZs6JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-obb.pt')\n",
        "\n",
        "results = model.train(data=f\"{dataset.location}/data.yaml\", epochs=20, imgsz=640)"
      ],
      "metadata": {
        "id": "Y_vEiP2Yvhzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=train epochs=20 imgsz=640 batch=8 plots=True \\\n",
        "model=yolov8n-obb.pt \\\n",
        "data={dataset.location}/data.yaml \\\n",
        "dropout=0.3"
      ],
      "metadata": {
        "id": "B-MmEkhKpV9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a model"
      ],
      "metadata": {
        "id": "szDpbeG4_MaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-6ESksE3_TNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18406ee-0ac1-4d93-b606-1b8247b929ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model = YOLO(\"/content/drive/MyDrive/license plate/best.pt\")"
      ],
      "metadata": {
        "id": "fRBsG86z_MCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQBHc5jy_gT_",
        "outputId": "ac03854c-55c6-4dd9-f787-d4a42bbeb4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'number', 1: 'province'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_test = '/content/-license-plates-2/test/images'"
      ],
      "metadata": {
        "id": "WWqqMkXR187F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(image_test, save=True, save_txt=True)\n",
        "pred"
      ],
      "metadata": {
        "id": "ea5anrkPOO8r",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "directory = '/content/runs/detect/predict'\n",
        "\n",
        "# ตรวจสอบว่าไดเรกทอรีนี้มีไฟล์ภาพหรือไม่\n",
        "if os.path.isdir(directory):\n",
        "    # หากมีไฟล์ภาพในไดเรกทอรี\n",
        "    image_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "    # แสดงภาพทีละภาพ\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(directory, image_file)\n",
        "        img = mpimg.imread(image_path)\n",
        "\n",
        "        plt.imshow(img)\n",
        "        plt.title(image_file)\n",
        "        plt.axis('off')  # ปิดแกน X และ Y\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"ไม่พบไดเรกทอรีที่ระบุ\")"
      ],
      "metadata": {
        "id": "mElbvZnke8Ie",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EasyOCR"
      ],
      "metadata": {
        "id": "3jMomz7vALOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "57dQ0rBWjvAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "pTQH9ctl7JMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "id": "XXIDL43PKv8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ไม่crop + เพิ่มแสง"
      ],
      "metadata": {
        "id": "d0Vvu48DU07h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install YOLOv8, EasyOCR, and OpenCV\n",
        "# !pip install ultralytics\n",
        "# !pip install easyocr\n",
        "# !pip install opencv-python-headless\n",
        "\n",
        "# Step 2: Import Required Libraries\n",
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "import numpy as np\n",
        "\n",
        "# Function to adjust brightness and contrast\n",
        "def adjust_brightness_contrast(image, brightness=0, contrast=0):\n",
        "    if brightness != 0:\n",
        "        if brightness > 0:\n",
        "            shadow = brightness\n",
        "            highlight = 255\n",
        "        else:\n",
        "            shadow = 0\n",
        "            highlight = 255 + brightness\n",
        "        alpha_b = (highlight - shadow) / 255\n",
        "        gamma_b = shadow\n",
        "        image = cv2.addWeighted(image, alpha_b, image, 0, gamma_b)\n",
        "\n",
        "    if contrast != 0:\n",
        "        f = 131 * (contrast + 127) / (127 * (131 - contrast))\n",
        "        alpha_c = f\n",
        "        gamma_c = 127 * (1 - f)\n",
        "        image = cv2.addWeighted(image, alpha_c, image, 0, gamma_c)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Function to denoise image\n",
        "def denoise_image(image):\n",
        "    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
        "\n",
        "# Function to increase brightness\n",
        "def increase_brightness(image, value=30):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "    v += value\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    image = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2RGB)\n",
        "    return image\n",
        "\n",
        "# Step 3: Load the YOLOv8 Model with Custom Weights\n",
        "model = YOLO('/content/drive/MyDrive/license plate/best.pt')  # Replace with the path to your weights file\n",
        "\n",
        "# Step 4: Load the Input Image\n",
        "input_image_path = '/content/-license-plates-2/test/images/CH1_20150510115910_3-2589_jpg.rf.a958732bf784a6be3d3cfa9810e56b8f.jpg'  # Replace with the path to your input image\n",
        "image = cv2.imread(input_image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "# Step 5: Perform Inference\n",
        "results = model.predict(image_rgb)\n",
        "\n",
        "# Step 6: Initialize EasyOCR Reader for Thai Language\n",
        "reader = easyocr.Reader(['th'])  # Specify 'th' for Thai language\n",
        "\n",
        "# Step 7: Process Each Detection and Apply EasyOCR\n",
        "output_image = image_rgb.copy()\n",
        "detected_texts = {'text_number': [], 'text_province': []}  # Dictionary to store texts by category\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Access the bounding box coordinates\n",
        "        class_id = int(box.cls)  # Access the class ID\n",
        "\n",
        "        # Extract the detected region\n",
        "        detected_region = image_rgb[y1:y2, x1:x2]\n",
        "\n",
        "        # Adjust brightness and contrast\n",
        "        adjusted_region = adjust_brightness_contrast(detected_region, brightness=20, contrast=20)\n",
        "\n",
        "        # Increase brightness\n",
        "        brightened_region = increase_brightness(adjusted_region, value=30)\n",
        "\n",
        "        # Denoise the brightened region\n",
        "        denoised_region = denoise_image(brightened_region)\n",
        "\n",
        "        # Resize the denoised region to the same size as the bounding box\n",
        "        resized_region = cv2.resize(denoised_region, (x2-x1, y2-y1), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # Replace the detected region with the processed region in the output image\n",
        "        output_image[y1:y2, x1:x2] = resized_region\n",
        "\n",
        "        # Apply EasyOCR to the resized region\n",
        "        ocr_result = reader.readtext(resized_region)\n",
        "\n",
        "        # Collect OCR result and categorize by class\n",
        "        for (bbox, text, prob) in ocr_result:\n",
        "            if class_id == 0:\n",
        "                detected_texts['text_number'].append(text)\n",
        "            elif class_id == 1:\n",
        "                detected_texts['text_province'].append(text)\n",
        "\n",
        "# Step 8: Display the Output Image with Processed Regions\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Print the OCR Results\n",
        "print(\"Detected Texts - Number:\")\n",
        "for text in detected_texts['text_number']:\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nDetected Texts - Province:\")\n",
        "for text in detected_texts['text_province']:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "GbVpct3YUAGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## crop + เพิ่มแสง"
      ],
      "metadata": {
        "id": "0e34ELs6GSfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install YOLOv8, EasyOCR, and OpenCV\n",
        "# !pip install ultralytics\n",
        "# !pip install easyocr\n",
        "# !pip install opencv-python-headless\n",
        "\n",
        "# Step 2: Import Required Libraries\n",
        "import cv2\n",
        "# import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "\n",
        "# Step 3: Load the YOLOv8 Model with Custom Weights\n",
        "model = YOLO('/content/drive/MyDrive/license plate/best.pt')  # Replace with the path to your weights file\n",
        "\n",
        "# Step 4: Load the Input Image and Adjust Brightness\n",
        "input_image_path = '/content/-license-plates-2/test/images/CH1_20150510115910_3-2589_jpg.rf.a958732bf784a6be3d3cfa9810e56b8f.jpg'  # Replace with the path to your input image\n",
        "image = cv2.imread(input_image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "# Adjust brightness\n",
        "brightness = 45  # Adjust brightness level as needed\n",
        "image_brightened = cv2.addWeighted(image_rgb, 1.0 + brightness / 100.0, image_rgb, 0, 0)\n",
        "\n",
        "# Step 5: Perform Inference\n",
        "results = model.predict(image_brightened)\n",
        "\n",
        "# Step 6: Initialize EasyOCR Reader for Thai Language\n",
        "reader = easyocr.Reader(['th'])  # Specify 'th' for Thai language\n",
        "\n",
        "# Step 7: Process Each Detection and Apply EasyOCR\n",
        "output_image = image_brightened.copy()  # Use the brightened image for processing\n",
        "detected_texts = {'text_number': [], 'text_province': []}  # Dictionary to store texts by category\n",
        "cropped_images = []\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Access the bounding box coordinates\n",
        "        class_id = int(box.cls)  # Access the class ID\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Extract the detected region and convert to grayscale\n",
        "        detected_region = cv2.cvtColor(image_brightened[y1:y2, x1:x2], cv2.COLOR_RGB2GRAY)\n",
        "        cropped_images.append((class_id, detected_region))\n",
        "\n",
        "        # Apply EasyOCR to the grayscale region\n",
        "        ocr_result = reader.readtext(detected_region)\n",
        "\n",
        "        # Collect OCR result and categorize by class\n",
        "        for (bbox, text, prob) in ocr_result:\n",
        "            if class_id == 0:\n",
        "                detected_texts['text_number'].append(text)\n",
        "            elif class_id == 1:\n",
        "                detected_texts['text_province'].append(text)\n",
        "\n",
        "# Step 8: Display the Output Image with Bounding Boxes\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Display Cropped Images of Each Class\n",
        "for idx, (class_id, cropped_image) in enumerate(cropped_images):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f'Class ID: {class_id}')\n",
        "    plt.imshow(cropped_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Step 10: Print the OCR Results\n",
        "print(\"Detected Texts - Number:\")\n",
        "for text in detected_texts['text_number']:\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nDetected Texts - Province:\")\n",
        "for text in detected_texts['text_province']:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "C7lkac1LHPEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install YOLOv8, EasyOCR, and OpenCV\n",
        "# !pip install ultralytics\n",
        "# !pip install easyocr\n",
        "# !pip install opencv-python-headless\n",
        "\n",
        "# Step 2: Import Required Libraries\n",
        "import cv2\n",
        "# import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "\n",
        "# Step 3: Load the YOLOv8 Model with Custom Weights\n",
        "model = YOLO('/content/drive/MyDrive/license plate/best.pt')  # Replace with the path to your weights file\n",
        "\n",
        "# Step 4: Load the Input Image and Adjust Brightness\n",
        "input_image_path = '/content/-license-plates-2/valid/images/CH1_20150510134337_3-6201_jpg.rf.80f5aa1e736df92645bff6abf814eafc.jpg'  # Replace with the path to your input image\n",
        "image = cv2.imread(input_image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "# Adjust brightness\n",
        "brightness = 45  # Adjust brightness level as needed\n",
        "image_brightened = cv2.addWeighted(image_rgb, 1.0 + brightness / 100.0, image_rgb, 0, 0)\n",
        "\n",
        "# Step 5: Perform Inference\n",
        "results = model.predict(image_brightened)\n",
        "\n",
        "# Step 6: Initialize EasyOCR Reader for Thai Language\n",
        "reader = easyocr.Reader(['th'])  # Specify 'th' for Thai language\n",
        "\n",
        "# Step 7: Process Each Detection and Apply EasyOCR\n",
        "output_image = image_brightened.copy()  # Use the brightened image for processing\n",
        "detected_texts = {'text_number': [], 'text_province': []}  # Dictionary to store texts by category\n",
        "cropped_images = []\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Access the bounding box coordinates\n",
        "        class_id = int(box.cls)  # Access the class ID\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Extract the detected region and convert to grayscale\n",
        "        detected_region = cv2.cvtColor(image_brightened[y1:y2, x1:x2], cv2.COLOR_RGB2GRAY)\n",
        "        cropped_images.append((class_id, detected_region))\n",
        "\n",
        "        # Apply EasyOCR to the grayscale region\n",
        "        ocr_result = reader.readtext(detected_region)\n",
        "\n",
        "        # Collect OCR result and categorize by class\n",
        "        for (bbox, text, prob) in ocr_result:\n",
        "            if class_id == 0:\n",
        "                detected_texts['text_number'].append(text)\n",
        "            elif class_id == 1:\n",
        "                detected_texts['text_province'].append(text)\n",
        "\n",
        "# Step 8: Display the Output Image with Bounding Boxes\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Display Cropped Images of Each Class\n",
        "for idx, (class_id, cropped_image) in enumerate(cropped_images):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f'Class ID: {class_id}')\n",
        "    plt.imshow(cropped_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Step 10: Print the OCR Results\n",
        "print(\"Detected Texts - Number:\")\n",
        "for text in detected_texts['text_number']:\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nDetected Texts - Province:\")\n",
        "for text in detected_texts['text_province']:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "hr-Iwh52Xb4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## crop + ปรับcontrast\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H5D3FmVUnr7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install YOLOv8, EasyOCR, and OpenCV\n",
        "# !pip install ultralytics\n",
        "# !pip install easyocr\n",
        "# !pip install opencv-python-headless\n",
        "\n",
        "# Step 2: Import Required Libraries\n",
        "import cv2\n",
        "# import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "\n",
        "# Step 3: Load the YOLOv8 Model with Custom Weights\n",
        "model = YOLO('/content/drive/MyDrive/license plate/best.pt')  # Replace with the path to your weights file\n",
        "\n",
        "# Step 4: Load the Input Image and Adjust Contrast\n",
        "input_image_path = '/content/-license-plates-2/test/images/CH1_20150510115910_3-2589_jpg.rf.a958732bf784a6be3d3cfa9810e56b8f.jpg'  # Replace with the path to your input image\n",
        "image = cv2.imread(input_image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "# Adjust contrast\n",
        "alpha = 3  # Contrast control (1.0-3.0)\n",
        "adjusted_image = cv2.convertScaleAbs(image_rgb, alpha=alpha, beta=0)\n",
        "\n",
        "# Step 5: Perform Inference\n",
        "results = model.predict(adjusted_image)\n",
        "\n",
        "# Step 6: Initialize EasyOCR Reader for Thai Language\n",
        "reader = easyocr.Reader(['th'])  # Specify 'th' for Thai language\n",
        "\n",
        "# Step 7: Process Each Detection and Apply EasyOCR\n",
        "output_image = adjusted_image.copy()  # Use the adjusted image for processing\n",
        "detected_texts = {'text_number': [], 'text_province': []}  # Dictionary to store texts by category\n",
        "cropped_images = []\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Access the bounding box coordinates\n",
        "        class_id = int(box.cls)  # Access the class ID\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Extract the detected region and convert to grayscale\n",
        "        detected_region = cv2.cvtColor(adjusted_image[y1:y2, x1:x2], cv2.COLOR_RGB2GRAY)\n",
        "        cropped_images.append((class_id, detected_region))\n",
        "\n",
        "        # Apply EasyOCR to the grayscale region\n",
        "        ocr_result = reader.readtext(detected_region)\n",
        "\n",
        "        # Collect OCR result and categorize by class\n",
        "        for (bbox, text, prob) in ocr_result:\n",
        "            if class_id == 0:\n",
        "                detected_texts['text_number'].append(text)\n",
        "            elif class_id == 1:\n",
        "                detected_texts['text_province'].append(text)\n",
        "\n",
        "# Step 8: Display the Output Image with Bounding Boxes\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Display Cropped Images of Each Class\n",
        "for idx, (class_id, cropped_image) in enumerate(cropped_images):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f'Class ID: {class_id}')\n",
        "    plt.imshow(cropped_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Step 10: Print the OCR Results\n",
        "print(\"Detected Texts - Number:\")\n",
        "for text in detected_texts['text_number']:\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nDetected Texts - Province:\")\n",
        "for text in detected_texts['text_province']:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "sB-9kmRunsVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ภาพที่ใช้ได้"
      ],
      "metadata": {
        "id": "dwxqmkwR8myl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ภาพที่ 1"
      ],
      "metadata": {
        "id": "2j-JCpRM8dtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install YOLOv8, EasyOCR, and OpenCV\n",
        "# !pip install ultralytics\n",
        "# !pip install easyocr\n",
        "# !pip install opencv-python-headless\n",
        "\n",
        "# Step 2: Import Required Libraries\n",
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "import numpy as np\n",
        "\n",
        "# Step 3: Load the YOLOv8 Model with Custom Weights\n",
        "model = YOLO('/content/drive/MyDrive/license plate/best.pt')  # Replace with the path to your weights file\n",
        "\n",
        "# Step 4: Load the Input Image\n",
        "input_image_path = '/content/drive/MyDrive/license plate/1.jpg'  # Replace with the path to your input image\n",
        "image = cv2.imread(input_image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "# Step 5: Perform Inference\n",
        "results = model.predict(image_rgb)\n",
        "\n",
        "# Step 6: Initialize EasyOCR Reader for Thai Language\n",
        "reader = easyocr.Reader(['th'])  # Specify 'th' for Thai language\n",
        "\n",
        "# Step 7: Process Each Detection and Apply EasyOCR\n",
        "output_image = image_rgb.copy()\n",
        "detected_texts = {'text_number': [], 'text_province': []}  # Dictionary to store texts by category\n",
        "cropped_images = []\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Access the bounding box coordinates\n",
        "        class_id = int(box.cls)  # Access the class ID\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Extract the detected region and convert to grayscale\n",
        "        detected_region = cv2.cvtColor(image_rgb[y1:y2, x1:x2], cv2.COLOR_RGB2GRAY)\n",
        "        cropped_images.append((class_id, detected_region))\n",
        "\n",
        "        # Apply EasyOCR to the grayscale region\n",
        "        ocr_result = reader.readtext(detected_region)\n",
        "\n",
        "        # Collect OCR result and categorize by class\n",
        "        for (bbox, text, prob) in ocr_result:\n",
        "            if class_id == 0:\n",
        "                detected_texts['text_number'].append(text)\n",
        "            elif class_id == 1:\n",
        "                detected_texts['text_province'].append(text)\n",
        "\n",
        "# Step 8: Display the Output Image with Bounding Boxes\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Display Cropped Images of Each Class\n",
        "for idx, (class_id, cropped_image) in enumerate(cropped_images):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f'Class ID: {class_id}')\n",
        "    plt.imshow(cropped_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Step 10: Print the OCR Results\n",
        "print(\"Detected Texts - Number:\")\n",
        "for text in detected_texts['text_number']:\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nDetected Texts - Province:\")\n",
        "for text in detected_texts['text_province']:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "yEucsjCH8dtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ภาพที่ 2"
      ],
      "metadata": {
        "id": "nLh8iq3MUylY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install YOLOv8, EasyOCR, and OpenCV\n",
        "# !pip install ultralytics\n",
        "# !pip install easyocr\n",
        "# !pip install opencv-python-headless\n",
        "\n",
        "# Step 2: Import Required Libraries\n",
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "import numpy as np\n",
        "\n",
        "# Step 3: Load the YOLOv8 Model with Custom Weights\n",
        "model = YOLO('/content/drive/MyDrive/license plate/best.pt')  # Replace with the path to your weights file\n",
        "\n",
        "# Step 4: Load the Input Image\n",
        "input_image_path = '/content/drive/MyDrive/license plate/2.jpg'  # Replace with the path to your input image\n",
        "image = cv2.imread(input_image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "# Step 5: Perform Inference\n",
        "results = model.predict(image_rgb)\n",
        "\n",
        "# Step 6: Initialize EasyOCR Reader for Thai Language\n",
        "reader = easyocr.Reader(['th'])  # Specify 'th' for Thai language\n",
        "\n",
        "# Step 7: Process Each Detection and Apply EasyOCR\n",
        "output_image = image_rgb.copy()\n",
        "detected_texts = {'text_number': [], 'text_province': []}  # Dictionary to store texts by category\n",
        "cropped_images = []\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Access the bounding box coordinates\n",
        "        class_id = int(box.cls)  # Access the class ID\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Extract the detected region and convert to grayscale\n",
        "        detected_region = cv2.cvtColor(image_rgb[y1:y2, x1:x2], cv2.COLOR_RGB2GRAY)\n",
        "        cropped_images.append((class_id, detected_region))\n",
        "\n",
        "        # Apply EasyOCR to the grayscale region\n",
        "        ocr_result = reader.readtext(detected_region)\n",
        "\n",
        "        # Collect OCR result and categorize by class\n",
        "        for (bbox, text, prob) in ocr_result:\n",
        "            if class_id == 0:\n",
        "                detected_texts['text_number'].append(text)\n",
        "            elif class_id == 1:\n",
        "                detected_texts['text_province'].append(text)\n",
        "\n",
        "# Step 8: Display the Output Image with Bounding Boxes\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Display Cropped Images of Each Class\n",
        "for idx, (class_id, cropped_image) in enumerate(cropped_images):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f'Class ID: {class_id}')\n",
        "    plt.imshow(cropped_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Step 10: Print the OCR Results\n",
        "print(\"Detected Texts - Number:\")\n",
        "for text in detected_texts['text_number']:\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nDetected Texts - Province:\")\n",
        "for text in detected_texts['text_province']:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "BBxNzNNPUwqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
