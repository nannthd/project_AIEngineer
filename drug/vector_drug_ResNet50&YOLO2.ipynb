{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTJ7nwxu86sLH/HMPS9WAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/vector_drug_ResNet50%26YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TFRiVLfDee5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a7af7d-afd7-437e-a045-20936f586cf5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_file, extract_folder):\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_folder)\n",
        "    print(f\"ไฟล์ {zip_file} ถูก unzip ไปที่ {extract_folder} แล้ว\")\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "zip_file = '/content/drive/MyDrive/drug/drug50cls_640.zip'  # เปลี่ยนเป็นชื่อไฟล์ที่ต้องการ unzip\n",
        "extract_folder = '/content/drug50cls_640'  # เปลี่ยนเป็นโฟลเดอร์ที่ต้องการที่จะ extract ไฟล์ไปที่นั่น\n",
        "\n",
        "unzip_file(zip_file, extract_folder)"
      ],
      "metadata": {
        "id": "yUhoQh_0ekJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "fmqvJFFJ76ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "RH-3QrQf8CkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ไม่ใช้YOLO"
      ],
      "metadata": {
        "id": "OYPVydd7oLi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# ระบุพาธไฟล์ ZIP ที่คุณต้องการจะแตก\n",
        "zip_file_path = '/content/drive/MyDrive/drug/drug50cls_640.zip'\n",
        "# ระบุพาธที่ต้องการเก็บไฟล์ที่แตกแล้ว\n",
        "extract_to_path = '/content/drug50cls_640'\n",
        "\n",
        "# แตกไฟล์ ZIP\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f'ไฟล์ ZIP ถูกแตกออกที่ {extract_to_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlNhhXXl9xEg",
        "outputId": "ea669907-09bc-4f5b-9dd2-4dd5cc6f2530"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไฟล์ ZIP ถูกแตกออกที่ /content/drug50cls_640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test more than 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image  # Import PIL for image handling\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def process_images_in_folder(folder_path, all_embeddings):\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(folder_path, image_file)\n",
        "            print(f\"Processing image: {image_file}\")\n",
        "\n",
        "            similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "            # แสดงภาพโดยใช้ matplotlib\n",
        "            img = image.load_img(image_path)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')  # ปิดแกน X และ Y\n",
        "            plt.show()\n",
        "\n",
        "            print(\"Top 5 most similar classes:\")\n",
        "            for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "                print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่ต้องการทดสอบ\n",
        "new_image_folder_path = '/content/drive/MyDrive/drug/test'\n",
        "\n",
        "# ประมวลผลรูปภาพทั้งหมดในโฟลเดอร์\n",
        "process_images_in_folder(new_image_folder_path, all_embeddings)"
      ],
      "metadata": {
        "id": "YodrnGjRAV_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ผิดไป 17class"
      ],
      "metadata": {
        "id": "XRPzKr5QEcjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ใช้YOLO"
      ],
      "metadata": {
        "id": "fHN98mVooHbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crop All\n",
        "import os\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/drug/model.pt')\n",
        "\n",
        "# Define the input path (can be a single image or a folder)\n",
        "path = '/content/drive/MyDrive/drug/test'\n",
        "\n",
        "# Define the crop directory\n",
        "crop_dir = '/content/CorpTest'\n",
        "os.makedirs(crop_dir, exist_ok=True)\n",
        "\n",
        "# Function to get image ID from file name\n",
        "def get_image_id(file_name):\n",
        "    return os.path.splitext(os.path.basename(file_name))[0]\n",
        "\n",
        "# Function to perform object detection and cropping\n",
        "def detect_and_crop(image_path, image_id):\n",
        "    # Predict with the YOLO model\n",
        "    results = model(image_path)\n",
        "\n",
        "    # Parse the results\n",
        "    detected = False\n",
        "    for result in results:\n",
        "        # Extract boxes, labels, and scores\n",
        "        boxes = result.boxes.xyxy  # x1, y1, x2, y2\n",
        "        labels = result.boxes.cls  # class ids\n",
        "        scores = result.boxes.conf  # confidence scores\n",
        "\n",
        "        # Convert tensor to numpy for easier processing\n",
        "        boxes = boxes.cpu().detach().numpy()\n",
        "        labels = labels.cpu().detach().numpy()\n",
        "        scores = scores.cpu().detach().numpy()\n",
        "\n",
        "        # Threshold for detection confidence\n",
        "        threshold = 0.3\n",
        "\n",
        "        # List of target labels (Replace with actual indices of your classes in the YOLO model)\n",
        "        target_labels = ['Amlopine_10mg', 'Amlopine_5mg', 'Anapril_5mg', 'Betalol-10-mg', 'Betalol-40-mg',\n",
        "                         'Blopress-16-mg', 'Blopress-8-mg', 'Blopress-Plus-16-mg', 'Blopress-Plus-8-mg',\n",
        "                         'Caduet-10_10-mg', 'Caduet-5_10-mg', 'Daonil-5-mg', 'Diamicron-MR-60-mg',\n",
        "                         'Diovan-160-mg', 'Diovan-80-mg', 'Forxiga-10-mg', 'Galvus-50-mg', 'Galvus_Met_50_1000mg',\n",
        "                         'Gliclazide_80mg', 'Gliparil-2-mg', 'Glucophage-500-mg', 'Glucophage-850-mg',\n",
        "                         'Glucophage-XR-1000-mg', 'Glucophage-XR-750-mg', 'Glyxambi-25_5-mg', 'Janumet-50_1000-mg',\n",
        "                         'Januvia-100-mg', 'Jardiance-10-mg', 'Jardiance-25-mg', 'Jardiance-Duo-12_5_1000-mg',\n",
        "                         'Lanzaar-100-mg', 'Lercadip-20-mg', 'Madiplot-10-mg', 'Madiplot_20mg',\n",
        "                         'Metoprolol_Stada_100mg', 'Micardis_40mg', 'Micardis_Plus_80_12_5mg', 'Minidiab_5mg',\n",
        "                         'Novonorm_1mg', 'Novonorm_2mg', 'Oseni_25_15mg', 'Poli_uretic', 'Prenolol_100mg',\n",
        "                         'Prenolol_25mg', 'Prenolol_50mg', 'Tanzaril_50mg', 'Utmos_15mg', 'Utmos_30mg',\n",
        "                         'Xigduo_XR_10_1000mg', 'Zanidip_10mg']\n",
        "\n",
        "        # Create a map from YOLO class index to target label\n",
        "        class_map = {i: label for i, label in enumerate(target_labels)}\n",
        "\n",
        "        # Check if any of the target labels are detected\n",
        "        for i, label in enumerate(labels):\n",
        "            if class_map[label] in target_labels and scores[i] >= threshold:\n",
        "                score = scores[i]\n",
        "                box = boxes[i]\n",
        "\n",
        "                # Get the coordinates and dimensions of the detected object\n",
        "                x1, y1, x2, y2 = box\n",
        "\n",
        "                # Open the original image\n",
        "                im = Image.open(image_path)\n",
        "\n",
        "                # Crop the image using the detected coordinates\n",
        "                im_crop = im.crop((x1, y1, x2, y2))\n",
        "\n",
        "                # Convert image mode to RGB if it's RGBA\n",
        "                if im_crop.mode == 'RGBA':\n",
        "                    im_crop = im_crop.convert('RGB')\n",
        "\n",
        "                # Save the cropped image with ID\n",
        "                crop_path = os.path.join(crop_dir, f'{image_id}.jpg')\n",
        "                im_crop.save(crop_path)\n",
        "                print(f\"Cropped image saved as '{crop_path}'.\")\n",
        "                detected = True\n",
        "                return image_id  # Return the image ID when successfully cropped\n",
        "\n",
        "    if not detected:\n",
        "        print(f\"Can't detect any target objects in image ID '{image_id}'.\")\n",
        "        return None  # Return None when no objects detected\n",
        "\n",
        "# Check if path is a file or directory\n",
        "if os.path.isfile(path):\n",
        "    image_id = get_image_id(path)\n",
        "    detect_and_crop(path, image_id)\n",
        "elif os.path.isdir(path):\n",
        "    # Loop through all files in the directory\n",
        "    for idx, file_name in enumerate(sorted(os.listdir(path))):\n",
        "        file_path = os.path.join(path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            image_id = f\"image{idx + 1}\"\n",
        "            detect_and_crop(file_path, image_id)\n",
        "else:\n",
        "    print(f\"Invalid path: {path}\")"
      ],
      "metadata": {
        "id": "xPOhXVf5FHw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test more than 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image  # Import PIL for image handling\n",
        "\n",
        "# ใช้โมเดล ResNet50 ของ TensorFlow ในการทำ embedding\n",
        "model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ResNet50\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    curr_df = pd.DataFrame(preds[0]).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def process_images_in_folder(folder_path, all_embeddings):\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(folder_path, image_file)\n",
        "            print(f\"Processing image: {image_file}\")\n",
        "\n",
        "            similar_classes = find_most_similar_classes(image_path, all_embeddings)\n",
        "\n",
        "            # แสดงภาพโดยใช้ matplotlib\n",
        "            img = image.load_img(image_path)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')  # ปิดแกน X และ Y\n",
        "            plt.show()\n",
        "\n",
        "            print(\"Top 5 most similar classes:\")\n",
        "            for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "                print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# โฟลเดอร์ที่ต้องการทดสอบ\n",
        "new_image_folder_path = '/content/CorpTest'\n",
        "\n",
        "# ประมวลผลรูปภาพทั้งหมดในโฟลเดอร์\n",
        "process_images_in_folder(new_image_folder_path, all_embeddings)"
      ],
      "metadata": {
        "id": "0chYumSDFsct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ผิดไป 3class"
      ],
      "metadata": {
        "id": "RREG0mB1IbLc"
      }
    }
  ]
}
