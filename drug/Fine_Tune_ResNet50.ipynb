{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "l4WQE2vLpvZp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/Fine_Tune_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MFf3kb_DvPIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ca211b-4113-4d0e-e328-e298538d2423"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/drug/data 50 class add_augment3.zip'"
      ],
      "metadata": {
        "id": "D1IXwa_xvQie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "B1lKkbcmLWVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "kLtaQol3zXu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-Tune ResNet50 (224)"
      ],
      "metadata": {
        "id": "l4WQE2vLpvZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import time\n",
        "\n",
        "# ตั้งค่าพารามิเตอร์\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "image_size = (224, 224)\n",
        "\n",
        "# ตรวจสอบว่า GPU สามารถใช้ได้หรือไม่\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# โหลดชุดข้อมูล\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# กำหนดเส้นทางไปยังชุดข้อมูล\n",
        "train_data_path = '/content/data 50 class add_augment'\n",
        "\n",
        "# สร้าง ImageFolder สำหรับชุดข้อมูลฝึก\n",
        "train_dataset = ImageFolder(root=train_data_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ตรวจสอบจำนวนคลาส\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "# โหลดโมเดล ResNet-50 ที่ผ่านการฝึกมาแล้ว\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# ตรึงเลเยอร์ทั้งหมด\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ปรับเปลี่ยนเลเยอร์สุดท้าย\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# ย้ายโมเดลไปที่อุปกรณ์ (GPU หรือ CPU)\n",
        "model.to(device)\n",
        "\n",
        "# เลือก optimizer และ loss function\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ฟังก์ชันเพื่อแปลงเวลาเป็นชั่วโมง, นาที, และวินาที\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    return f'{hours}h {minutes}m {secs}s'\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.train()\n",
        "start_time = time.time()  # เริ่มจับเวลา\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()  # เริ่มจับเวลาแต่ละ epoch\n",
        "    for inputs, labels in train_loader:\n",
        "        # ย้ายข้อมูลไปที่อุปกรณ์ (GPU หรือ CPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_time = time.time() - epoch_start_time  # เวลาที่ใช้ในแต่ละ epoch\n",
        "    total_time = time.time() - start_time  # เวลาทั้งหมดที่ใช้ในการฝึก\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Epoch Time: {format_time(epoch_time)}, Total Time: {format_time(total_time)}')\n",
        "\n",
        "print(f'Finished Training. Total Time: {format_time(total_time)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrfSuxqdTvLy",
        "outputId": "070228d9-574b-4d4c-b418-cb03c7937aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 50\n",
            "Epoch 1/10, Loss: 0.721778154373169, Epoch Time: 0h 3m 18s, Total Time: 0h 3m 18s\n",
            "Epoch 2/10, Loss: 0.33759504556655884, Epoch Time: 0h 3m 14s, Total Time: 0h 6m 32s\n",
            "Epoch 3/10, Loss: 0.07416685670614243, Epoch Time: 0h 3m 15s, Total Time: 0h 9m 48s\n",
            "Epoch 4/10, Loss: 0.055027905851602554, Epoch Time: 0h 3m 13s, Total Time: 0h 13m 1s\n",
            "Epoch 5/10, Loss: 0.03758874535560608, Epoch Time: 0h 3m 13s, Total Time: 0h 16m 15s\n",
            "Epoch 6/10, Loss: 0.22012344002723694, Epoch Time: 0h 3m 12s, Total Time: 0h 19m 27s\n",
            "Epoch 7/10, Loss: 0.02919219620525837, Epoch Time: 0h 3m 13s, Total Time: 0h 22m 41s\n",
            "Epoch 8/10, Loss: 0.03523397445678711, Epoch Time: 0h 3m 14s, Total Time: 0h 25m 55s\n",
            "Epoch 9/10, Loss: 0.01805408112704754, Epoch Time: 0h 3m 12s, Total Time: 0h 29m 8s\n",
            "Epoch 10/10, Loss: 0.05058996379375458, Epoch Time: 0h 3m 17s, Total Time: 0h 32m 26s\n",
            "Finished Training. Total Time: 0h 32m 26s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# เซฟโมเดล\n",
        "model_save_path = './model_resnet50_224.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f'Model saved to {model_save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isiZDfwGmPAx",
        "outputId": "cff27ef6-48d9-4545-cf47-c156840f8d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./model_resnet50_224.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = model_save_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_224.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f'Model saved to {model_save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5jJAnmYo6_2",
        "outputId": "fdb77e1b-fb88-4cd1-d437-efe1228a5be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/drug/newtrain/model_resnet50_224.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-Tune ResNet50 (640)"
      ],
      "metadata": {
        "id": "lk_D8IS9p6u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import time\n",
        "\n",
        "# ตั้งค่าพารามิเตอร์\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "image_size = (640, 640)\n",
        "\n",
        "# ตรวจสอบว่า GPU สามารถใช้ได้หรือไม่\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# โหลดชุดข้อมูล\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# กำหนดเส้นทางไปยังชุดข้อมูล\n",
        "train_data_path = '/content/data 50 class add_augment'\n",
        "\n",
        "# สร้าง ImageFolder สำหรับชุดข้อมูลฝึก\n",
        "train_dataset = ImageFolder(root=train_data_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ตรวจสอบจำนวนคลาส\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "# โหลดโมเดล ResNet-50 ที่ผ่านการฝึกมาแล้ว\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# ตรึงเลเยอร์ทั้งหมด\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ปรับเปลี่ยนเลเยอร์สุดท้าย\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# ย้ายโมเดลไปที่อุปกรณ์ (GPU หรือ CPU)\n",
        "model.to(device)\n",
        "\n",
        "# เลือก optimizer และ loss function\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ฟังก์ชันเพื่อแปลงเวลาเป็นชั่วโมง, นาที, และวินาที\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    return f'{hours}h {minutes}m {secs}s'\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.train()\n",
        "start_time = time.time()  # เริ่มจับเวลา\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()  # เริ่มจับเวลาแต่ละ epoch\n",
        "    for inputs, labels in train_loader:\n",
        "        # ย้ายข้อมูลไปที่อุปกรณ์ (GPU หรือ CPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_time = time.time() - epoch_start_time  # เวลาที่ใช้ในแต่ละ epoch\n",
        "    total_time = time.time() - start_time  # เวลาทั้งหมดที่ใช้ในการฝึก\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Epoch Time: {format_time(epoch_time)}, Total Time: {format_time(total_time)}')\n",
        "\n",
        "print(f'Finished Training. Total Time: {format_time(total_time)}')"
      ],
      "metadata": {
        "id": "JndaXu4Hp-LC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb1d4b4-773d-4f82-ba56-bc88649bc0eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 156MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.1659988164901733, Epoch Time: 0h 4m 32s, Total Time: 0h 4m 32s\n",
            "Epoch 2/10, Loss: 0.6981589198112488, Epoch Time: 0h 4m 23s, Total Time: 0h 8m 55s\n",
            "Epoch 3/10, Loss: 0.133559450507164, Epoch Time: 0h 4m 26s, Total Time: 0h 13m 22s\n",
            "Epoch 4/10, Loss: 0.6324554681777954, Epoch Time: 0h 4m 22s, Total Time: 0h 17m 45s\n",
            "Epoch 5/10, Loss: 0.13220003247261047, Epoch Time: 0h 4m 26s, Total Time: 0h 22m 11s\n",
            "Epoch 6/10, Loss: 0.11460687965154648, Epoch Time: 0h 4m 23s, Total Time: 0h 26m 35s\n",
            "Epoch 7/10, Loss: 0.11895160377025604, Epoch Time: 0h 4m 23s, Total Time: 0h 30m 59s\n",
            "Epoch 8/10, Loss: 0.20608116686344147, Epoch Time: 0h 4m 21s, Total Time: 0h 35m 22s\n",
            "Epoch 9/10, Loss: 0.08346973359584808, Epoch Time: 0h 4m 22s, Total Time: 0h 39m 44s\n",
            "Epoch 10/10, Loss: 0.2149277627468109, Epoch Time: 0h 4m 21s, Total Time: 0h 44m 6s\n",
            "Finished Training. Total Time: 0h 44m 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# เซฟโมเดล\n",
        "model_save_path = './model_resnet50_640.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f'Model saved to {model_save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1b608e-2c33-4eee-a93c-5ed529cdc284",
        "id": "Xbvaos5dca-W"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./model_resnet50_640.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = model_save_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_640.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f'Model saved to {model_save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd684c8-189f-4e5d-ad02-3539eb50e142",
        "id": "emmMm6Qsca-X"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/drug/FineTune/model_resnet50_640.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#image2vector"
      ],
      "metadata": {
        "id": "c62x2H09prW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##224*224"
      ],
      "metadata": {
        "id": "OvsJErezpz3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50cls"
      ],
      "metadata": {
        "id": "gCNHvKQWp18U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_224.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def process_images_in_folder(folder_path, output_csv_path):\n",
        "    pdEmbedded = pd.DataFrame()\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    print(f\"Processing images in folder: {folder_path}\")\n",
        "\n",
        "    for idx, image_file in enumerate(tqdm(image_files, desc=\"Processing images\", unit=\"image\")):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        embedded = image_embedding(image_path)\n",
        "        embedded['ID'] = image_file  # Add ID column to the DataFrame\n",
        "        pdEmbedded = pd.concat([pdEmbedded, embedded], ignore_index=True)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_folder = os.path.dirname(output_csv_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save DataFrame to CSV\n",
        "    pdEmbedded.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Saved embedding data for {folder_path} to {output_csv_path}\")\n",
        "\n",
        "def process_all_folders(base_folder_path, output_base_folder):\n",
        "    subfolders = [f.path for f in os.scandir(base_folder_path) if f.is_dir()]\n",
        "\n",
        "    print(f\"Processing folders in base directory: {base_folder_path}\")\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_name = os.path.basename(subfolder)\n",
        "        output_csv_path = os.path.join(output_base_folder, f\"{subfolder_name}.csv\")\n",
        "        process_images_in_folder(subfolder, output_csv_path)\n",
        "        print(f\"Completed processing for folder: {subfolder_name}\")\n",
        "\n",
        "# Example usage\n",
        "base_folder_path = '/content/data 50 class add_augment'\n",
        "output_base_folder = '/content/Vector_ResNet50_FT224'\n",
        "os.makedirs(output_base_folder, exist_ok=True)\n",
        "\n",
        "process_all_folders(base_folder_path, output_base_folder)"
      ],
      "metadata": {
        "id": "y7ODMevt24CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Data drug50cls\n",
        "# Define the folder you want to zip and download\n",
        "import shutil\n",
        "\n",
        "folder_to_download = '/content/Vector_ResNet50_FT224'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/drive/MyDrive/drug/FineTune/Vector_ResNet50_FT224', 'zip', folder_to_download)\n",
        "\n",
        "# # Download the zip file\n",
        "# from google.colab import files\n",
        "# files.download('/content/drive/MyDrive/drug/FineTune/content/Vector_ResNet50_FT224.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AR-bvSVbtd9Q",
        "outputId": "487451e1-0ec4-4375-cf7e-e4622fb273dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/drug/FineTune/Vector_ResNet50_FT224.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine similarity"
      ],
      "metadata": {
        "id": "nyzLWmM3t88A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/model_resnet50.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # Drop ID column and keep only class embeddings\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # Compute similarity between new image embedding and class embeddings\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/ResNet50_FT_model_v1'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# Image to test\n",
        "new_image_path = '/content/cropped_11_0_0.jpg'\n",
        "\n",
        "# Find top 5 most similar classes\n",
        "similar_classes = find_most_similar_classes(new_image_path, all_embeddings)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 most similar classes:\")\n",
        "for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "    print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBw2LQ1l6tHU",
        "outputId": "e055ffc1-5812-4b67-ffb9-82ed5dfc124e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most similar classes:\n",
            "1. Class: Novonorm2mg, Similarity Score: 0.8101994092840938\n",
            "2. Class: Novonorm1mg, Similarity Score: 0.7914134416210582\n",
            "3. Class: BlopressPlus8mg, Similarity Score: 0.7524376232783746\n",
            "4. Class: Prenolol50mg, Similarity Score: 0.7453936909688319\n",
            "5. Class: Amlopine10mg, Similarity Score: 0.7168482991407736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##640*640"
      ],
      "metadata": {
        "id": "p9DF5aaK-KeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50cls"
      ],
      "metadata": {
        "id": "DGI8Ztg3-KeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/FineTune/model_resnet50_640.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def process_images_in_folder(folder_path, output_csv_path):\n",
        "    pdEmbedded = pd.DataFrame()\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    print(f\"Processing images in folder: {folder_path}\")\n",
        "\n",
        "    for idx, image_file in enumerate(tqdm(image_files, desc=\"Processing images\", unit=\"image\")):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        embedded = image_embedding(image_path)\n",
        "        embedded['ID'] = image_file  # Add ID column to the DataFrame\n",
        "        pdEmbedded = pd.concat([pdEmbedded, embedded], ignore_index=True)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_folder = os.path.dirname(output_csv_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save DataFrame to CSV\n",
        "    pdEmbedded.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Saved embedding data for {folder_path} to {output_csv_path}\")\n",
        "\n",
        "def process_all_folders(base_folder_path, output_base_folder):\n",
        "    subfolders = [f.path for f in os.scandir(base_folder_path) if f.is_dir()]\n",
        "\n",
        "    print(f\"Processing folders in base directory: {base_folder_path}\")\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_name = os.path.basename(subfolder)\n",
        "        output_csv_path = os.path.join(output_base_folder, f\"{subfolder_name}.csv\")\n",
        "        process_images_in_folder(subfolder, output_csv_path)\n",
        "        print(f\"Completed processing for folder: {subfolder_name}\")\n",
        "\n",
        "# Example usage\n",
        "base_folder_path = '/content/data 50 class add_augment'\n",
        "output_base_folder = '/content/Vector_ResNet50_FT640'\n",
        "os.makedirs(output_base_folder, exist_ok=True)\n",
        "\n",
        "process_all_folders(base_folder_path, output_base_folder)"
      ],
      "metadata": {
        "id": "qia5oBhK-KeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Data drug50cls\n",
        "# Define the folder you want to zip and download\n",
        "import shutil\n",
        "\n",
        "folder_to_download = '/content/Vector_ResNet50_FT640'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/drive/MyDrive/drug/FineTune/Vector_ResNet50_FT640', 'zip', folder_to_download)\n",
        "\n",
        "# # Download the zip file\n",
        "# from google.colab import files\n",
        "# files.download('/content/drive/MyDrive/drug/drug50cls_ResNet50_FT_model_v1_640.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0f23fe9d-1c68-4f24-9499-9945f5992f62",
        "id": "lRk9AgJovb5a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/drug/FineTune/Vector_ResNet50_FT640.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine similarity"
      ],
      "metadata": {
        "id": "fnEFdOldvb5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/trained_resnet50_epoch_24.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # Drop ID column and keep only class embeddings\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # Compute similarity between new image embedding and class embeddings\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/ResNet50_FT_model_v1_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# Image to test\n",
        "new_image_path = '/content/cropped_11_0_0.jpg'\n",
        "\n",
        "# Find top 5 most similar classes\n",
        "similar_classes = find_most_similar_classes(new_image_path, all_embeddings)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 most similar classes:\")\n",
        "for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "    print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b86013d-961f-4d4f-a96a-2afdeb9274a4",
        "id": "rOu4yxT3vb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most similar classes:\n",
            "1. Class: Novonorm2mg, Similarity Score: 0.9064162646280978\n",
            "2. Class: Novonorm1mg, Similarity Score: 0.8640252960489345\n",
            "3. Class: BlopressPlus8mg, Similarity Score: 0.8330473335570844\n",
            "4. Class: Forxiga10mg, Similarity Score: 0.8227136119137224\n",
            "5. Class: MetoprololStada100mg, Similarity Score: 0.8203953731375324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/trained_resnet50_epoch_24.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # Drop ID column and keep only class embeddings\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # Compute similarity between new image embedding and class embeddings\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "def display_image_with_similarities(image_path, similar_classes):\n",
        "    img = Image.open(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Top 5 most similar classes:\")\n",
        "    plt.show()\n",
        "\n",
        "    for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "        print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/ResNet50_FT_model_v1_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# Folder containing new images to test\n",
        "new_images_folder = '/content/test'\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for image_filename in os.listdir(new_images_folder):\n",
        "    new_image_path = os.path.join(new_images_folder, image_filename)\n",
        "    if new_image_path.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        similar_classes = find_most_similar_classes(new_image_path, all_embeddings)\n",
        "\n",
        "        # Display image and results\n",
        "        display_image_with_similarities(new_image_path, similar_classes)"
      ],
      "metadata": {
        "id": "m1B1LaeupYih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
