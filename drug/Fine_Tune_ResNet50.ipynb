{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "l4WQE2vLpvZp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/Fine_Tune_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFf3kb_DvPIP",
        "outputId": "03cf7f9d-94d2-4527-e7f4-993c8d732343"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/drug/data 50 class add_augment.zip'"
      ],
      "metadata": {
        "id": "D1IXwa_xvQie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "B1lKkbcmLWVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-Tune ResNet50 (224)"
      ],
      "metadata": {
        "id": "l4WQE2vLpvZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import time\n",
        "\n",
        "# ตั้งค่าพารามิเตอร์\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "image_size = (224, 224)\n",
        "\n",
        "# โหลดชุดข้อมูล\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# กำหนดเส้นทางไปยังชุดข้อมูล\n",
        "train_data_path = '/content/data 50 class add_augment - Copy'\n",
        "\n",
        "# สร้าง ImageFolder สำหรับชุดข้อมูลฝึก\n",
        "train_dataset = ImageFolder(root=train_data_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ตรวจสอบจำนวนคลาส\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "# โหลดโมเดล ResNet-50 ที่ผ่านการฝึกมาแล้ว\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# ตรึงเลเยอร์ทั้งหมด\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ปรับเปลี่ยนเลเยอร์สุดท้าย\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# เลือก optimizer และ loss function\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ฟังก์ชันเพื่อแปลงเวลาเป็นชั่วโมง, นาที, และวินาที\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    return f'{hours}h {minutes}m {secs}s'\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.train()\n",
        "start_time = time.time()  # เริ่มจับเวลา\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()  # เริ่มจับเวลาแต่ละ epoch\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_time = time.time() - epoch_start_time  # เวลาที่ใช้ในแต่ละ epoch\n",
        "    total_time = time.time() - start_time  # เวลาทั้งหมดที่ใช้ในการฝึก\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Epoch Time: {format_time(epoch_time)}, Total Time: {format_time(total_time)}')\n",
        "\n",
        "print(f'Finished Training. Total Time: {format_time(total_time)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4Hf4XfwCY_7",
        "outputId": "7eef38ef-70d1-4853-f341-8b3f520e99aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6731619238853455, Epoch Time: 0h 10m 34s, Total Time: 0h 10m 34s\n",
            "Epoch 2/5, Loss: 0.2915046811103821, Epoch Time: 0h 10m 35s, Total Time: 0h 21m 10s\n",
            "Epoch 3/5, Loss: 0.1838056445121765, Epoch Time: 0h 10m 38s, Total Time: 0h 31m 49s\n",
            "Epoch 4/5, Loss: 0.06550140678882599, Epoch Time: 0h 10m 50s, Total Time: 0h 42m 40s\n",
            "Epoch 5/5, Loss: 0.20829328894615173, Epoch Time: 0h 11m 1s, Total Time: 0h 53m 42s\n",
            "Finished Training. Total Time: 0h 53m 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# เซฟโมเดล\n",
        "model_save_path = './model_resnet50.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f'Model saved to {model_save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isiZDfwGmPAx",
        "outputId": "ac67c5d8-33b7-4e04-9f34-b0cc7db67c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./model_resnet50.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = model_save_path = '/content/drive/MyDrive/drug/model_resnet50.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f'Model saved to {model_save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5jJAnmYo6_2",
        "outputId": "7f928d20-8bd1-4044-cd80-75fb5b7d8fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/drug/model_resnet50.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-Tune ResNet50 (640)"
      ],
      "metadata": {
        "id": "lk_D8IS9p6u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# ตั้งค่าพารามิเตอร์\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "image_size = (640, 640)\n",
        "\n",
        "# โหลดชุดข้อมูล\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# กำหนดเส้นทางไปยังชุดข้อมูล\n",
        "train_data_path = '/content/data 50 class add_augment - Copy'\n",
        "\n",
        "# สร้าง ImageFolder สำหรับชุดข้อมูลฝึก\n",
        "train_dataset = ImageFolder(root=train_data_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ตรวจสอบจำนวนคลาส\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "# โหลดโมเดล ResNet-50 ที่ผ่านการฝึกมาแล้ว\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# ตรึงเลเยอร์ทั้งหมด\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ปรับเปลี่ยนเลเยอร์สุดท้าย\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# เลือก optimizer และ loss function\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ฟังก์ชันเพื่อแปลงเวลาเป็นชั่วโมง, นาที, และวินาที\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    return f'{hours}h {minutes}m {secs}s'\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.train()\n",
        "start_time = time.time()  # เริ่มจับเวลา\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()  # เริ่มจับเวลาแต่ละ epoch\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # ใช้ tqdm สำหรับ progress bar\n",
        "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix({\"Loss\": running_loss / (pbar.n + 1)})\n",
        "            pbar.update(1)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start_time  # เวลาที่ใช้ในแต่ละ epoch\n",
        "    total_time = time.time() - start_time  # เวลาทั้งหมดที่ใช้ในการฝึก\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}, Epoch Time: {format_time(epoch_time)}, Total Time: {format_time(total_time)}')\n",
        "\n",
        "    # บันทึกโมเดลในแต่ละ epoch\n",
        "    epoch_model_save_path = f'/content/trained_resnet50_epoch_{epoch+1}.pth'\n",
        "    torch.save(model.state_dict(), epoch_model_save_path)\n",
        "    print(f'Model saved to {epoch_model_save_path}')\n",
        "\n",
        "print(f'Finished Training. Total Time: {format_time(total_time)}')\n",
        "\n",
        "# บันทึกโมเดลสุดท้าย\n",
        "final_model_save_path = '/content/trained_resnet50_final.pth'\n",
        "torch.save(model.state_dict(), final_model_save_path)\n",
        "print(f'Model saved to {final_model_save_path}')"
      ],
      "metadata": {
        "id": "JndaXu4Hp-LC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db3afc6-ffa9-457c-b9ed-151a6b5d63be"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 62.0MB/s]\n",
            "Epoch 1/5: 100%|██████████| 125/125 [1:07:21<00:00, 32.33s/batch, Loss=2.9]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 2.90180012512207, Epoch Time: 1h 7m 21s, Total Time: 1h 7m 21s\n",
            "Model saved to /content/trained_resnet50_epoch_1.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 125/125 [1:06:14<00:00, 31.80s/batch, Loss=1.03]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5, Loss: 1.0305347344875335, Epoch Time: 1h 6m 14s, Total Time: 2h 13m 35s\n",
            "Model saved to /content/trained_resnet50_epoch_2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 125/125 [1:06:59<00:00, 32.16s/batch, Loss=0.514]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Loss: 0.5141067585945129, Epoch Time: 1h 6m 59s, Total Time: 3h 20m 35s\n",
            "Model saved to /content/trained_resnet50_epoch_3.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5:  24%|██▍       | 30/125 [16:52<50:32, 31.92s/batch, Loss=0.371]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#image2vector"
      ],
      "metadata": {
        "id": "c62x2H09prW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##224*224"
      ],
      "metadata": {
        "id": "OvsJErezpz3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50cls"
      ],
      "metadata": {
        "id": "gCNHvKQWp18U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "qjVqg9Mupzex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/model_resnet50.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def process_images_in_folder(folder_path, output_csv_path):\n",
        "    pdEmbedded = pd.DataFrame()\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    print(f\"Processing images in folder: {folder_path}\")\n",
        "\n",
        "    for idx, image_file in enumerate(tqdm(image_files, desc=\"Processing images\", unit=\"image\")):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        embedded = image_embedding(image_path)\n",
        "        embedded['ID'] = image_file  # Add ID column to the DataFrame\n",
        "        pdEmbedded = pd.concat([pdEmbedded, embedded], ignore_index=True)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_folder = os.path.dirname(output_csv_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save DataFrame to CSV\n",
        "    pdEmbedded.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Saved embedding data for {folder_path} to {output_csv_path}\")\n",
        "\n",
        "def process_all_folders(base_folder_path, output_base_folder):\n",
        "    subfolders = [f.path for f in os.scandir(base_folder_path) if f.is_dir()]\n",
        "\n",
        "    print(f\"Processing folders in base directory: {base_folder_path}\")\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_name = os.path.basename(subfolder)\n",
        "        output_csv_path = os.path.join(output_base_folder, f\"{subfolder_name}.csv\")\n",
        "        process_images_in_folder(subfolder, output_csv_path)\n",
        "        print(f\"Completed processing for folder: {subfolder_name}\")\n",
        "\n",
        "# Example usage\n",
        "base_folder_path = '/content/data 50 class add_augment - Copy'\n",
        "output_base_folder = '/content/ResNet50_FT_model_v1'\n",
        "os.makedirs(output_base_folder, exist_ok=True)\n",
        "\n",
        "process_all_folders(base_folder_path, output_base_folder)"
      ],
      "metadata": {
        "id": "y7ODMevt24CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Data drug50cls\n",
        "# Define the folder you want to zip and download\n",
        "import shutil\n",
        "\n",
        "folder_to_download = '/content/ResNet50_FT_model_v1'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/drive/MyDrive/drug/drug50cls_ResNet50_FT_model_v1', 'zip', folder_to_download)\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/drug/drug50cls_ResNet50_FT_model_v1.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "AR-bvSVbtd9Q",
        "outputId": "922fd5f0-8431-4af5-d6ce-a057dffd20c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4f005de8-7cdb-4462-996c-9638fc7a11ec\", \"drug50cls_ResNet50_FT_model_v1.zip\", 18983559)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine similarity"
      ],
      "metadata": {
        "id": "nyzLWmM3t88A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/model_resnet50.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # Drop ID column and keep only class embeddings\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # Compute similarity between new image embedding and class embeddings\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '/content/ResNet50_FT_model_v1'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# Image to test\n",
        "new_image_path = '/content/cropped_11_0_0.jpg'\n",
        "\n",
        "# Find top 5 most similar classes\n",
        "similar_classes = find_most_similar_classes(new_image_path, all_embeddings)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 most similar classes:\")\n",
        "for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "    print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBw2LQ1l6tHU",
        "outputId": "e055ffc1-5812-4b67-ffb9-82ed5dfc124e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most similar classes:\n",
            "1. Class: Novonorm2mg, Similarity Score: 0.8101994092840938\n",
            "2. Class: Novonorm1mg, Similarity Score: 0.7914134416210582\n",
            "3. Class: BlopressPlus8mg, Similarity Score: 0.7524376232783746\n",
            "4. Class: Prenolol50mg, Similarity Score: 0.7453936909688319\n",
            "5. Class: Amlopine10mg, Similarity Score: 0.7168482991407736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##640*640"
      ],
      "metadata": {
        "id": "p9DF5aaK-KeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50cls"
      ],
      "metadata": {
        "id": "DGI8Ztg3-KeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "PLaKDUJF-KeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/trained_resnet50_epoch_3.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def process_images_in_folder(folder_path, output_csv_path):\n",
        "    pdEmbedded = pd.DataFrame()\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    print(f\"Processing images in folder: {folder_path}\")\n",
        "\n",
        "    for idx, image_file in enumerate(tqdm(image_files, desc=\"Processing images\", unit=\"image\")):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        embedded = image_embedding(image_path)\n",
        "        embedded['ID'] = image_file  # Add ID column to the DataFrame\n",
        "        pdEmbedded = pd.concat([pdEmbedded, embedded], ignore_index=True)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_folder = os.path.dirname(output_csv_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save DataFrame to CSV\n",
        "    pdEmbedded.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Saved embedding data for {folder_path} to {output_csv_path}\")\n",
        "\n",
        "def process_all_folders(base_folder_path, output_base_folder):\n",
        "    subfolders = [f.path for f in os.scandir(base_folder_path) if f.is_dir()]\n",
        "\n",
        "    print(f\"Processing folders in base directory: {base_folder_path}\")\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_name = os.path.basename(subfolder)\n",
        "        output_csv_path = os.path.join(output_base_folder, f\"{subfolder_name}.csv\")\n",
        "        process_images_in_folder(subfolder, output_csv_path)\n",
        "        print(f\"Completed processing for folder: {subfolder_name}\")\n",
        "\n",
        "# Example usage\n",
        "base_folder_path = '/content/data 50 class add_augment - Copy'\n",
        "output_base_folder = '/content/ResNet50_FT_model_v1_640'\n",
        "os.makedirs(output_base_folder, exist_ok=True)\n",
        "\n",
        "process_all_folders(base_folder_path, output_base_folder)"
      ],
      "metadata": {
        "id": "qia5oBhK-KeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Data drug50cls\n",
        "# Define the folder you want to zip and download\n",
        "import shutil\n",
        "\n",
        "folder_to_download = '/content/ResNet50_FT_model_v1_640'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/drive/MyDrive/drug/drug50cls_ResNet50_FT_model_v1_640', 'zip', folder_to_download)\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/drug/drug50cls_ResNet50_FT_model_v1_640.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "85e5f642-07c8-4601-92b2-2af874d71068",
        "id": "lRk9AgJovb5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_878af606-7c02-4f7b-a5ca-219090a96f1c\", \"drug50cls_ResNet50_FT_model_v1_640.zip\", 18631395)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine similarity"
      ],
      "metadata": {
        "id": "fnEFdOldvb5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a feature extractor model\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize ResNet-50 model and feature extractor\n",
        "resnet50_model = models.resnet50(pretrained=False)\n",
        "num_classes = 50  # Replace with the actual number of classes from your training\n",
        "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)  # Replace the final layer with your trained layer\n",
        "model_path = '/content/drive/MyDrive/drug/trained_resnet50_epoch_3.pth'\n",
        "resnet50_model.load_state_dict(torch.load(model_path))\n",
        "feature_extractor = FeatureExtractor(resnet50_model).to(device)\n",
        "feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB')  # Convert image to RGB\n",
        "    img = transform(img).unsqueeze(0).to(device)  # Apply transformation and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the penultimate layer\n",
        "        features = feature_extractor(img)\n",
        "        avg_embedding = features.squeeze().cpu().numpy()  # Convert to numpy array and remove batch dimension\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # Use CSV file name as class name\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # Drop ID column and keep only class embeddings\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # Compute similarity between new image embedding and class embeddings\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # Get highest similarity score in class\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "# Load embeddings from CSV folder\n",
        "csv_folder_path = '//content/ResNet50_FT_model_v1_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# Image to test\n",
        "new_image_path = '/content/cropped_11_0_0.jpg'\n",
        "\n",
        "# Find top 5 most similar classes\n",
        "similar_classes = find_most_similar_classes(new_image_path, all_embeddings)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 most similar classes:\")\n",
        "for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "    print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a21654-5641-4db8-be91-8c612ad1500b",
        "id": "rOu4yxT3vb5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most similar classes:\n",
            "1. Class: Novonorm2mg, Similarity Score: 0.8982210943885162\n",
            "2. Class: Novonorm1mg, Similarity Score: 0.8595769598268738\n",
            "3. Class: BlopressPlus8mg, Similarity Score: 0.8298161234179119\n",
            "4. Class: Diovan80mg, Similarity Score: 0.818381833972657\n",
            "5. Class: Forxiga10mg, Similarity Score: 0.8161373944369158\n"
          ]
        }
      ]
    }
  ]
}
