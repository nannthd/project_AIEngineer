{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/Fine_Tune_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine-Tune ViT**"
      ],
      "metadata": {
        "id": "DLDq4DmFkVr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZcJCLHYvWe0",
        "outputId": "f39444d4-b39f-4dbd-e197-bbc18ce47f76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/drug/data 50 class add_augment3.zip'"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UZ37dEJtl7fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to your directory containing subfolders\n",
        "img_dir = '/content/data 50 class add_augment'  # Adjust this path to your dataset\n",
        "\n",
        "# Initialize an empty list to store folder names\n",
        "folder_names = []\n",
        "\n",
        "# Check if the main directory exists\n",
        "if not os.path.exists(img_dir):\n",
        "    print(f\"Directory not found: {img_dir}\")\n",
        "else:\n",
        "    # Loop through each subfolder in the image directory\n",
        "    for folder_name in os.listdir(img_dir):\n",
        "        folder_path = os.path.join(img_dir, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            print(f\"Found folder: {folder_name}\")  # Debug print\n",
        "            folder_names.append(folder_name)\n",
        "\n",
        "# Create a DataFrame\n",
        "if folder_names:\n",
        "    df = pd.DataFrame(folder_names, columns=[\"class_name\"])\n",
        "    # Save the DataFrame to a CSV file\n",
        "    labels_file = '/content/labels.csv'  # Adjust this path to where you want to save folder_names.csv\n",
        "    df.to_csv(labels_file, index=False)\n",
        "    print(f\"Folder names CSV file saved to {labels_file}\")\n",
        "    # Print the DataFrame to check the collected data\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"No subfolders found. Please check the directory structure.\")"
      ],
      "metadata": {
        "id": "vNcT2cRkx7vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from transformers import ViTForImageClassification, TrainingArguments, Trainer, default_data_collator\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# สร้างไฟล์ labels.csv\n",
        "def create_labels_csv(img_dir, labels_file):\n",
        "    img_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # เดินไปยังโฟลเดอร์หลัก\n",
        "    for folder_name in os.listdir(img_dir):\n",
        "        folder_path = os.path.join(img_dir, folder_name)\n",
        "\n",
        "        if os.path.isdir(folder_path):\n",
        "            # เดินไปยังไฟล์ภาพในโฟลเดอร์ย่อย\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                img_paths.append(img_path)\n",
        "                labels.append(folder_name)\n",
        "\n",
        "    # สร้าง DataFrame และบันทึกเป็น CSV\n",
        "    df = pd.DataFrame({\n",
        "        'image_path': img_paths,\n",
        "        'class_name': labels\n",
        "    })\n",
        "    df.to_csv(labels_file, index=False)\n",
        "\n",
        "# กำหนดพาธ\n",
        "img_dir = '/content/data 50 class add_augment'\n",
        "labels_file = '/content/labels.csv'\n",
        "\n",
        "# สร้างไฟล์ labels.csv\n",
        "create_labels_csv(img_dir, labels_file)\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_dir, labels_file, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.img_labels = pd.read_csv(labels_file)\n",
        "        self.label_map = {name: idx for idx, name in enumerate(self.img_labels['class_name'].unique())}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_labels.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label_name = self.img_labels.iloc[idx, 1]\n",
        "        label = self.label_map[label_name]  # Convert class name to integer label\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return {'pixel_values': image, 'labels': torch.tensor(label, dtype=torch.long)}\n",
        "\n",
        "# Define transforms\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),  # Use the size expected by ViT model\n",
        "    CenterCrop(224),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create dataset\n",
        "dataset = CustomDataset(img_dir=img_dir, labels_file=labels_file, transform=transform)\n",
        "\n",
        "# Load Pre-trained Model และ Feature Extractor\n",
        "model_name = \"google/vit-base-patch16-224-in21k\"\n",
        "NUM_CLASSES = len(pd.read_csv(labels_file)['class_name'].unique())  # Number of unique classes\n",
        "model = ViTForImageClassification.from_pretrained(model_name, num_labels=NUM_CLASSES)\n",
        "\n",
        "# Check if GPU is available and move model to GPU if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define Data Collator\n",
        "data_collator = default_data_collator\n",
        "\n",
        "# Define Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps=1500,\n",
        "    save_steps=1500,\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"tensorboard\",  # Optional: report to TensorBoard\n",
        ")\n",
        "\n",
        "# Define Trainer และ Train Model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    eval_dataset=dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=None,  # Set to None if not using a tokenizer\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "nNm5tGUC2AP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดโมเดล\n",
        "# Export Data drug50cls\n",
        "# Define the folder you want to zip and download\n",
        "import shutil\n",
        "\n",
        "folder_to_download = '/content/results/checkpoint-3000'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/drive/MyDrive/drug/FineTune/model_VIT_224', 'zip', folder_to_download)\n",
        "\n",
        "# # Download the zip file\n",
        "# from google.colab import files\n",
        "# files.download('/content/drive/MyDrive/drug/FineTune/model_VIT_224.zip')"
      ],
      "metadata": {
        "id": "Wz8BWJD8AD5D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1c29dc1d-81a6-43bd-997d-de0bc662054c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/drug/FineTune/model_VIT_224.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##224*224"
      ],
      "metadata": {
        "id": "uP3i_Zcr1XFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50cls"
      ],
      "metadata": {
        "id": "lS0wPwVK1acR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use VIT model to convert data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "# โหลดโมเดล ViT และ Processor\n",
        "model_path = '/content/results/checkpoint-3000'  # เปลี่ยนเป็น path ที่ถูกต้อง\n",
        "model = ViTModel.from_pretrained(model_path)  # ใช้ ViTModel แทน ViTForImageClassification\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "    inputs = processor(images=img, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    avg_embedding = last_hidden_states.mean(dim=1).squeeze().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def process_images_in_folder(folder_path, output_csv_path):\n",
        "    pdEmbedded = pd.DataFrame()\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for idx, image_file in enumerate(image_files):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        embedded = image_embedding(image_path)\n",
        "        embedded['ID'] = image_file  # ใช้ชื่อไฟล์เป็น ID\n",
        "        pdEmbedded = pd.concat([pdEmbedded, embedded], ignore_index=True)\n",
        "\n",
        "    # สร้างโฟลเดอร์สำหรับ output_csv_path\n",
        "    output_folder = os.path.dirname(output_csv_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # บันทึก DataFrame ลงในไฟล์ CSV\n",
        "    pdEmbedded.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# ฟังก์ชันสำหรับการวนลูปโฟลเดอร์\n",
        "def process_all_folders(base_folder_path, output_base_folder):\n",
        "    subfolders = [f.path for f in os.scandir(base_folder_path) if f.is_dir()]\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_name = os.path.basename(subfolder)\n",
        "        output_csv_path = os.path.join(output_base_folder, f\"{subfolder_name}.csv\")\n",
        "        process_images_in_folder(subfolder, output_csv_path)\n",
        "        print(f\"Embedding data for {subfolder_name} has been saved to {output_csv_path}\")\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "base_folder_path = \"/content/data 50 class add_augment\"\n",
        "output_base_folder = \"/content/Vector_VIT_FT224\"\n",
        "os.makedirs(output_base_folder, exist_ok=True)  # สร้างโฟลเดอร์หลักถ้ายังไม่มี\n",
        "\n",
        "process_all_folders(base_folder_path, output_base_folder)"
      ],
      "metadata": {
        "id": "86ecusk8ABM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดข้อมูลเวกเตอร์224*224\n",
        "# Export Data drug50cls\n",
        "# Define the folder you want to zip and download\n",
        "import shutil\n",
        "\n",
        "folder_to_download = '/content/Vector_VIT_FT224'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/drive/MyDrive/drug/FineTune/Vector_VIT_FT224', 'zip', folder_to_download)\n",
        "\n",
        "# # Download the zip file\n",
        "# from google.colab import files\n",
        "# files.download('/content/drive/MyDrive/drug/FineTune/Vector_VIT_FT224.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eC2JokB_WI-5",
        "outputId": "98864acd-2f48-4e55-be31-12fae2068712"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/drug/FineTune/Vector_VIT_FT224.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine similarity"
      ],
      "metadata": {
        "id": "SAile6ON1xLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('/content/results/checkpoint-3000')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/Vector_VIT_FT224'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# รูปภาพที่ต้องการทดสอบ\n",
        "new_image_path = '/content/1.jpg'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "similar_classes = find_most_similar_classes(new_image_path, all_embeddings)\n",
        "\n",
        "# แสดงผลลัพธ์\n",
        "print(\"Top 5 most similar classes:\")\n",
        "for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "    print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8hmRcpcS0tb",
        "outputId": "c08f734a-0303-42d0-cdfb-26d54013878f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at /content/results/checkpoint-1250 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most similar classes:\n",
            "1. Class: Amlopine5mg, Similarity Score: 0.7520281472894522\n",
            "2. Class: Amlopine10mg, Similarity Score: 0.38829910199583983\n",
            "3. Class: Prenolol25mg, Similarity Score: 0.3289244473260224\n",
            "4. Class: Prenolol100mg, Similarity Score: 0.2969507488183878\n",
            "5. Class: Janumet50_1000mg, Similarity Score: 0.2915699594577877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#640*640"
      ],
      "metadata": {
        "id": "L8ZIW96X4Rnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50cls"
      ],
      "metadata": {
        "id": "q2e30a4e4Rn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use VIT model to convert data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "def image_embedding(path):\n",
        "    img = Image.open(path).convert('RGB').resize((640, 640))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "    inputs = processor(images=img, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    avg_embedding = last_hidden_states.mean(dim=1).squeeze().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "\n",
        "    curr_df = pd.DataFrame(avg_embedding).T\n",
        "    return curr_df\n",
        "\n",
        "def process_images_in_folder(folder_path, output_csv_path):\n",
        "    pdEmbedded = pd.DataFrame()\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for idx, image_file in enumerate(image_files):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        embedded = image_embedding(image_path)\n",
        "        embedded['ID'] = image_file  # ใช้ชื่อไฟล์เป็น ID\n",
        "        pdEmbedded = pd.concat([pdEmbedded, embedded], ignore_index=True)\n",
        "\n",
        "    # สร้างโฟลเดอร์สำหรับ output_csv_path\n",
        "    output_folder = os.path.dirname(output_csv_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # บันทึก DataFrame ลงในไฟล์ CSV\n",
        "    pdEmbedded.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# ฟังก์ชันสำหรับการวนลูปโฟลเดอร์\n",
        "def process_all_folders(base_folder_path, output_base_folder):\n",
        "    subfolders = [f.path for f in os.scandir(base_folder_path) if f.is_dir()]\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_name = os.path.basename(subfolder)\n",
        "        output_csv_path = os.path.join(output_base_folder, f\"{subfolder_name}.csv\")\n",
        "        process_images_in_folder(subfolder, output_csv_path)\n",
        "        print(f\"Embedding data for {subfolder_name} has been saved to {output_csv_path}\")\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "base_folder_path = \"/content/data 50 class add_augment\"\n",
        "output_base_folder = \"/content/Vector_VIT_FT640\"\n",
        "os.makedirs(output_base_folder, exist_ok=True)  # สร้างโฟลเดอร์หลักถ้ายังไม่มี\n",
        "\n",
        "process_all_folders(base_folder_path, output_base_folder)"
      ],
      "metadata": {
        "id": "nVIxIO604RoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดข้อมูลเวกเต640*640\n",
        "# Export Data drug50cls\n",
        "# Define the folder you want to zip and download\n",
        "import shutil\n",
        "\n",
        "folder_to_download = '/content/Vector_VIT_FT640'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/drive/MyDrive/drug/FineTune/Vector_VIT_FT640', 'zip', folder_to_download)\n",
        "\n",
        "# # Download the zip file\n",
        "# from google.colab import files\n",
        "# files.download('/content/drive/MyDrive/drug/FineTune/Vector_VIT_FT640.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QCvU_T3EUQC6",
        "outputId": "702d3323-57c7-458d-a572-8ec068ac162f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/drug/FineTune/Vector_VIT_FT640.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cosine similarity"
      ],
      "metadata": {
        "id": "g89YhXaD4f5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# ใช้โมเดล ViT ของ Hugging Face ในการทำ embedding\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ย้ายโมเดลไปยัง GPU ถ้ามี\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def image_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB').resize((224, 224))  # ปรับขนาดภาพให้เข้ากับ ViT\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        avg_embedding = last_hidden_states.mean(dim=1).squeeze().cpu().detach().numpy()  # ค่าเฉลี่ยของ hidden states\n",
        "        curr_df = pd.DataFrame(avg_embedding).T\n",
        "        return curr_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_embeddings_from_csv(csv_folder):\n",
        "    all_embeddings = {}\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            class_name = os.path.splitext(csv_file)[0]  # ใช้ชื่อไฟล์ CSV เป็นชื่อคลาส\n",
        "            csv_path = os.path.join(csv_folder, csv_file)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # ดรอปคอลัมน์ ID และเก็บเฉพาะเวกเตอร์ของคลาส\n",
        "            embeddings_no_id = df.drop(['ID'], axis=1)\n",
        "            all_embeddings[class_name] = embeddings_no_id\n",
        "    return all_embeddings\n",
        "\n",
        "def find_most_similar_classes(new_image_path, all_embeddings):\n",
        "    new_embedding = image_embedding(new_image_path)\n",
        "    similarity_scores = {}\n",
        "\n",
        "    for class_name, embeddings_df in all_embeddings.items():\n",
        "        # คำนวณค่า similarity ระหว่าง embedding ของรูปภาพใหม่กับ embeddings ของคลาส\n",
        "        similarity_score = cosine_similarity(new_embedding, embeddings_df)\n",
        "        max_similarity_score = similarity_score.max()  # หา similarity ที่สูงที่สุดในคลาส\n",
        "        similarity_scores[class_name] = max_similarity_score\n",
        "\n",
        "    sorted_similarity = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_5_similar_classes = sorted_similarity[:5]\n",
        "\n",
        "    return top_5_similar_classes\n",
        "\n",
        "# โหลด embedding จากโฟลเดอร์ที่เก็บไฟล์ CSV\n",
        "csv_folder_path = '/content/drug50cls_ViTModel_640'\n",
        "all_embeddings = load_embeddings_from_csv(csv_folder_path)\n",
        "\n",
        "# รูปภาพที่ต้องการทดสอบ\n",
        "new_image_path = '/content/2.jpg'\n",
        "\n",
        "# ค้นหาคลาสที่มีความคล้ายกันที่สุด 5 อันดับ\n",
        "similar_classes = find_most_similar_classes(new_image_path, all_embeddings)\n",
        "\n",
        "# แสดงผลลัพธ์\n",
        "print(\"Top 5 most similar classes:\")\n",
        "for rank, (class_name, similarity_score) in enumerate(similar_classes, start=1):\n",
        "    print(f\"{rank}. Class: {class_name}, Similarity Score: {similarity_score}\")"
      ],
      "metadata": {
        "id": "TZm_Nj-d4frh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}