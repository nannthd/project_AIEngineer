{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTcuh66D+d3r01ulXMTDYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/vector_drug_CLIPModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/openai/clip-vit-large-patch14"
      ],
      "metadata": {
        "id": "N_KGG5_E8Ba8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09naVNrv6xpb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
        "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Image-text similarity scores:\", logits_per_image)\n",
        "print(\"Label probabilities:\", probs)"
      ],
      "metadata": {
        "id": "98TCYaF6-6Ob",
        "outputId": "15343ba8-27c9-4720-aa09-878eb00495cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image-text similarity scores: tensor([[18.9041, 11.7159]], grad_fn=<TBackward0>)\n",
            "Label probabilities: tensor([[9.9925e-01, 7.5487e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ลอง"
      ],
      "metadata": {
        "id": "K8qBs_juAI3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3cxk7pea6WJT",
        "outputId": "54a857bd-cd98-422a-f93f-e0d8995b2aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/drug/data 50 class add_augment.zip'"
      ],
      "metadata": {
        "id": "qVmwOPgi6r8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Path to the main directory containing 50 subfolders\n",
        "main_directory = \"/content/data 50 class add_augment - Copy\"\n",
        "\n",
        "# Prepare lists to store rows for CSV\n",
        "rows = []\n",
        "\n",
        "# Start timer for the whole process\n",
        "start_time = datetime.now()\n",
        "\n",
        "# Collect images and text labels from the subfolders and convert them to vectors\n",
        "for folder_name in os.listdir(main_directory):\n",
        "    folder_path = os.path.join(main_directory, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        text_label = folder_name\n",
        "\n",
        "        # Start timer for the current folder\n",
        "        folder_start_time = datetime.now()\n",
        "\n",
        "        # Collect all images from the current folder\n",
        "        image_files = [os.path.join(folder_path, image_name) for image_name in os.listdir(folder_path)]\n",
        "\n",
        "        for image_path in image_files:\n",
        "            # Open the image\n",
        "            image = Image.open(image_path)\n",
        "\n",
        "            # Prepare the inputs for the CLIP model\n",
        "            inputs = processor(text=[text_label], images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            # Get the image and text embeddings\n",
        "            image_embedding = outputs.image_embeds.squeeze().tolist()\n",
        "            text_embedding = outputs.text_embeds.squeeze().tolist()\n",
        "\n",
        "            # Create a row for the CSV\n",
        "            row = [text_label, image_path] + image_embedding + text_embedding\n",
        "            rows.append(row)\n",
        "\n",
        "        # End timer for the current folder\n",
        "        folder_end_time = datetime.now()\n",
        "        folder_duration = folder_end_time - folder_start_time\n",
        "        print(f\"Converted vectors for folder: {folder_name} in {folder_duration}\")\n",
        "\n",
        "# End timer for the whole process\n",
        "end_time = datetime.now()\n",
        "total_duration = end_time - start_time\n",
        "\n",
        "# Define the header for the CSV file\n",
        "header = ['TextLabel', 'ImagePath'] + [f'ImageEmbed_{i}' for i in range(len(image_embedding))] + [f'TextEmbed_{i}' for i in range(len(text_embedding))]\n",
        "\n",
        "# Write the data to a CSV file\n",
        "csv_file_path = '/content/class_vectors.csv'\n",
        "df = pd.DataFrame(rows, columns=header)\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Vectors have been successfully saved to: {csv_file_path}\")\n",
        "print(f\"Total time for processing all folders: {total_duration}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F6TtnwSUvIo",
        "outputId": "e9c2385f-5704-49b8-dd54-a192e68def50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted vectors for folder: Janumet50_1000mg in 0:02:29.272910\n",
            "Converted vectors for folder: Prenolol50mg in 0:02:22.600846\n",
            "Converted vectors for folder: Glyxambi25_5mg in 0:02:30.322592\n",
            "Converted vectors for folder: Madiplot20mg in 0:02:26.075998\n",
            "Converted vectors for folder: GlucophageXR1000mg in 0:02:25.581881\n",
            "Converted vectors for folder: Amlopine10mg in 0:02:23.748385\n",
            "Converted vectors for folder: Caduet5_10mg in 0:02:23.690538\n",
            "Converted vectors for folder: Glucophage500mg in 0:02:25.931969\n",
            "Converted vectors for folder: Betalol10mg in 0:02:23.035979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvM6dhev5zyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Path to your local image file\n",
        "image_path = \"/content/data 50 class add_augment - Copy/Betalol40mg/Betalol40mg_bright.jpg\"\n",
        "\n",
        "# Open the image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Define multiple text labels for comparison\n",
        "text_labels = ['Amlopine_10mg', 'Amlopine_5mg', 'Anapril_5mg', 'Betalol-10-mg', 'Betalol-40-mg',\n",
        "               'Blopress-16-mg', 'Blopress-8-mg', 'Blopress-Plus-16-mg', 'Blopress-Plus-8-mg',\n",
        "               'Caduet-10_10-mg', 'Caduet-5_10-mg', 'Daonil-5-mg', 'Diamicron-MR-60-mg',\n",
        "               'Diovan-160-mg', 'Diovan-80-mg', 'Forxiga-10-mg', 'Galvus-50-mg', 'Galvus_Met_50_1000mg',\n",
        "               'Gliclazide_80mg', 'Gliparil-2-mg', 'Glucophage-500-mg', 'Glucophage-850-mg',\n",
        "               'Glucophage-XR-1000-mg', 'Glucophage-XR-750-mg', 'Glyxambi-25_5-mg', 'Janumet-50_1000-mg',\n",
        "               'Januvia-100-mg', 'Jardiance-10-mg', 'Jardiance-25-mg', 'Jardiance-Duo-12_5_1000-mg',\n",
        "               'Lanzaar-100-mg', 'Lercadip-20-mg', 'Madiplot-10-mg', 'Madiplot_20mg',\n",
        "               'Metoprolol_Stada_100mg', 'Micardis_40mg', 'Micardis_Plus_80_12_5mg', 'Minidiab_5mg',\n",
        "               'Novonorm_1mg', 'Novonorm_2mg', 'Oseni_25_15mg', 'Poli_uretic', 'Prenolol_100mg',\n",
        "               'Prenolol_25mg', 'Prenolol_50mg', 'Tanzaril_50mg', 'Utmos_15mg', 'Utmos_30mg',\n",
        "               'Xigduo_XR_10_1000mg', 'Zanidip_10mg']\n",
        "\n",
        "# Prepare the inputs for the CLIP model\n",
        "inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Forward pass through the model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Get the image-text similarity scores\n",
        "logits_per_image = outputs.logits_per_image\n",
        "\n",
        "# Compute the probabilities\n",
        "probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "# Get the top 5 similarity scores and their corresponding text labels\n",
        "top_probs, top_indices = probs.topk(5, dim=1)\n",
        "\n",
        "# Convert to lists for easier manipulation\n",
        "top_probs = top_probs.squeeze().tolist()\n",
        "top_indices = top_indices.squeeze().tolist()\n",
        "\n",
        "# Print the top 5 similarity scores and their corresponding text labels in descending order\n",
        "print(\"Top 5 similarity scores and corresponding text labels:\")\n",
        "for i, idx in enumerate(top_indices):\n",
        "    print(f\"{text_labels[idx]}: {top_probs[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFgcxaUlL108",
        "outputId": "3f853071-e129-460c-d42b-74373d3d79cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 similarity scores and corresponding text labels:\n",
            "Betalol-40-mg: 0.7764\n",
            "Betalol-10-mg: 0.1812\n",
            "Prenolol_50mg: 0.0250\n",
            "Prenolol_100mg: 0.0084\n",
            "Prenolol_25mg: 0.0051\n"
          ]
        }
      ]
    }
  ]
}