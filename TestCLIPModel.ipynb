{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NUIG9Q6xD9mS"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nannthd/project_AIEngineer/blob/main/TestCLIPModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hd0BHWpCdXd",
        "outputId": "b44f1361-508b-4eb7-9d44-aa9b809cce51"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/drug/data 50 class add_augment3.zip'"
      ],
      "metadata": {
        "id": "xrpx_R9FCj8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#image + text เทียบimage"
      ],
      "metadata": {
        "id": "-glSCU0rA757"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Load the CSV file containing the vectors\n",
        "csv_file_path = '/content/drive/MyDrive/drug/FineTune/CLIPModel/class_vectors.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract the text labels and embeddings from the CSV\n",
        "text_labels = df['TextLabel'].tolist()\n",
        "image_embeddings = df[[col for col in df.columns if 'ImageEmbed_' in col]].values\n",
        "text_embeddings = df[[col for col in df.columns if 'TextEmbed_' in col]].values\n",
        "\n",
        "# Convert embeddings from lists to numpy arrays\n",
        "image_embeddings = np.array(image_embeddings)\n",
        "text_embeddings = np.array(text_embeddings)\n",
        "\n",
        "def compare_image_with_stored_vectors(new_image_path):\n",
        "    # Open the new image\n",
        "    image = Image.open(new_image_path)\n",
        "\n",
        "    # Prepare the inputs for the CLIP model\n",
        "    inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Forward pass through the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the image embedding for the new image\n",
        "    new_image_embedding = outputs.image_embeds.squeeze().cpu().numpy().reshape(1, -1)  # Ensure 2D array\n",
        "\n",
        "    # Compute cosine similarity between new image embedding and stored image embeddings\n",
        "    image_similarities = cosine_similarity(new_image_embedding, image_embeddings)\n",
        "    text_similarities = cosine_similarity(new_image_embedding, text_embeddings)\n",
        "\n",
        "    # Combine similarities (weighted average can be adjusted if needed)\n",
        "    combined_similarities = (image_similarities + text_similarities) / 2\n",
        "\n",
        "    # Get index of the most similar class\n",
        "    most_similar_index = np.argmax(combined_similarities, axis=1)[0]\n",
        "\n",
        "    # Return the predicted label\n",
        "    predicted_label = text_labels[most_similar_index]\n",
        "    return predicted_label\n",
        "\n",
        "# Process all images in the base folder\n",
        "base_folder = '/content/drive/MyDrive/drug/CorpTest'  # Base folder containing images\n",
        "\n",
        "# Initialize lists to store results\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "for image_file in os.listdir(base_folder):\n",
        "    image_path = os.path.join(base_folder, image_file)\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
        "        # Extract true class from the image file name (e.g., 'ClassName_1.jpg')\n",
        "        true_label = os.path.splitext(image_file)[0]\n",
        "\n",
        "        print(f\"\\nProcessing image: {image_path}\")\n",
        "        predicted_label = compare_image_with_stored_vectors(image_path)\n",
        "\n",
        "        predicted_labels.append(predicted_label)\n",
        "        true_labels.append(true_label)\n",
        "\n",
        "# Create a sorted list of unique class labels\n",
        "labels = sorted(set(true_labels + predicted_labels))  # All unique class labels, sorted alphabetically\n",
        "\n",
        "# Create a confusion matrix\n",
        "confusion_matrix = np.zeros((len(labels), len(labels)), dtype=int)\n",
        "\n",
        "for true, pred in zip(true_labels, predicted_labels):\n",
        "    true_index = labels.index(true)\n",
        "    pred_index = labels.index(pred)\n",
        "    confusion_matrix[true_index, pred_index] += 1\n",
        "\n",
        "# Create a heatmap from the confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05OhIXz6S-Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#image เทียบtext"
      ],
      "metadata": {
        "id": "NUIG9Q6xD9mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Path to your local image file\n",
        "image_path = \"/content/drive/MyDrive/drug/CorpTest/Caduet5_10mg.jpg\"\n",
        "\n",
        "# Open the image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Define multiple text labels for comparison\n",
        "text_labels = [\n",
        "    'Amlopine10mg', 'Amlopine5mg', 'Anapril5mg', 'Betalol10mg', 'Betalol40mg',\n",
        "    'Blopress16mg', 'Blopress8mg', 'BlopressPlus16mg', 'BlopressPlus8mg', 'Caduet10_10mg',\n",
        "    'Caduet5_10mg', 'Daonil5mg', 'DiamicronMR60mg', 'Diovan160mg', 'Diovan80mg',\n",
        "    'Forxiga10mg', 'Galvus50mg', 'GalvusMet50_1000mg', 'Gliclazide80mg', 'Gliparil2mg',\n",
        "    'Glucophage500mg', 'Glucophage850mg', 'GlucophageXR1000mg', 'GlucophageXR750mg', 'Glyxambi25_5mg',\n",
        "    'Janumet50_1000mg', 'Januvia100mg', 'Jardiance10mg', 'Jardiance25mg', 'JardianceDuo12.5_1000mg',\n",
        "    'Lanzaar100mg', 'Lercadip20mg', 'Madiplot10mg', 'Madiplot20mg', 'MetoprololStada100mg',\n",
        "    'Micardis40mg', 'MicardisPlus80_12.5mg', 'Minidiab5mg', 'Novonorm1mg', 'Novonorm2mg',\n",
        "    'Oseni25_15mg', 'Poli_uretic', 'Prenolol100mg', 'Prenolol25mg', 'Prenolol50mg',\n",
        "    'Tanzaril50mg', 'Utmos15mg', 'Utmos30mg', 'XigduoXR10_1000mg', 'Zanidip10mg'\n",
        "]\n",
        "\n",
        "# Prepare the inputs for the CLIP model\n",
        "inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Forward pass through the model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Get the image-text similarity scores\n",
        "logits_per_image = outputs.logits_per_image\n",
        "\n",
        "# Compute the probabilities\n",
        "probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "# Get the top 5 similarity scores and their corresponding text labels\n",
        "top_probs, top_indices = probs.topk(5, dim=1)\n",
        "\n",
        "# Convert to lists for easier manipulation\n",
        "top_probs = top_probs.squeeze().tolist()\n",
        "top_indices = top_indices.squeeze().tolist()\n",
        "\n",
        "# Print the top 5 similarity scores and their corresponding text labels in descending order\n",
        "print(\"Top 5 similarity scores and corresponding text labels:\")\n",
        "for i, idx in enumerate(top_indices):\n",
        "    print(f\"{text_labels[idx]}: {top_probs[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aQrIqA2POX8",
        "outputId": "de00158d-91ae-4c80-db80-3520e67b35d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 similarity scores and corresponding text labels:\n",
            "Caduet5_10mg: 0.2959\n",
            "GalvusMet50_1000mg: 0.2251\n",
            "Caduet10_10mg: 0.1914\n",
            "Madiplot10mg: 0.1615\n",
            "Madiplot20mg: 0.0378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Path to your local image folder\n",
        "image_folder_path = \"/content/drive/MyDrive/drug/CorpTest\"\n",
        "\n",
        "# Define multiple text labels for comparison\n",
        "text_labels = [\n",
        "    'Amlopine10mg', 'Amlopine5mg', 'Anapril5mg', 'Betalol10mg', 'Betalol40mg',\n",
        "    'Blopress16mg', 'Blopress8mg', 'BlopressPlus16mg', 'BlopressPlus8mg', 'Caduet10_10mg',\n",
        "    'Caduet5_10mg', 'Daonil5mg', 'DiamicronMR60mg', 'Diovan160mg', 'Diovan80mg',\n",
        "    'Forxiga10mg', 'Galvus50mg', 'GalvusMet50_1000mg', 'Gliclazide80mg', 'Gliparil2mg',\n",
        "    'Glucophage500mg', 'Glucophage850mg', 'GlucophageXR1000mg', 'GlucophageXR750mg', 'Glyxambi25_5mg',\n",
        "    'Janumet50_1000mg', 'Januvia100mg', 'Jardiance10mg', 'Jardiance25mg', 'JardianceDuo12.5_1000mg',\n",
        "    'Lanzaar100mg', 'Lercadip20mg', 'Madiplot10mg', 'Madiplot20mg', 'MetoprololStada100mg',\n",
        "    'Micardis40mg', 'MicardisPlus80_12.5mg', 'Minidiab5mg', 'Novonorm1mg', 'Novonorm2mg',\n",
        "    'Oseni25_15mg', 'Poli_uretic', 'Prenolol100mg', 'Prenolol25mg', 'Prenolol50mg',\n",
        "    'Tanzaril50mg', 'Utmos15mg', 'Utmos30mg', 'XigduoXR10_1000mg', 'Zanidip10mg'\n",
        "]\n",
        "\n",
        "# Loop through all image files in the folder\n",
        "for filename in os.listdir(image_folder_path):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Check for valid image files\n",
        "        image_path = os.path.join(image_folder_path, filename)\n",
        "\n",
        "        # Open the image\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Prepare the inputs for the CLIP model\n",
        "        inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # Get the image-text similarity scores\n",
        "        logits_per_image = outputs.logits_per_image\n",
        "\n",
        "        # Compute the probabilities\n",
        "        probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "        # Get the top 5 similarity scores and their corresponding text labels\n",
        "        top_probs, top_indices = probs.topk(5, dim=1)\n",
        "\n",
        "        # Convert to lists for easier manipulation\n",
        "        top_probs = top_probs.squeeze().tolist()\n",
        "        top_indices = top_indices.squeeze().tolist()\n",
        "\n",
        "        # Print the results for this image\n",
        "        print(f\"\\nResults for {filename}:\")\n",
        "        for i, idx in enumerate(top_indices):\n",
        "            print(f\"{text_labels[idx]}: {top_probs[i]:.4f}\")"
      ],
      "metadata": {
        "id": "q7Pm3pm9XJgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Path to your image folder\n",
        "image_folder = \"/content/drive/MyDrive/drug/CorpTest\"\n",
        "\n",
        "# Define multiple text labels for comparison\n",
        "text_labels = [\n",
        "    'Amlopine10mg', 'Amlopine5mg', 'Anapril5mg', 'Betalol10mg', 'Betalol40mg',\n",
        "    'Blopress16mg', 'Blopress8mg', 'BlopressPlus16mg', 'BlopressPlus8mg', 'Caduet10_10mg',\n",
        "    'Caduet5_10mg', 'Daonil5mg', 'DiamicronMR60mg', 'Diovan160mg', 'Diovan80mg',\n",
        "    'Forxiga10mg', 'Galvus50mg', 'GalvusMet50_1000mg', 'Gliclazide80mg', 'Gliparil2mg',\n",
        "    'Glucophage500mg', 'Glucophage850mg', 'GlucophageXR1000mg', 'GlucophageXR750mg', 'Glyxambi25_5mg',\n",
        "    'Janumet50_1000mg', 'Januvia100mg', 'Jardiance10mg', 'Jardiance25mg', 'JardianceDuo12.5_1000mg',\n",
        "    'Lanzaar100mg', 'Lercadip20mg', 'Madiplot10mg', 'Madiplot20mg', 'MetoprololStada100mg',\n",
        "    'Micardis40mg', 'MicardisPlus80_12.5mg', 'Minidiab5mg', 'Novonorm1mg', 'Novonorm2mg',\n",
        "    'Oseni25_15mg', 'Poli_uretic', 'Prenolol100mg', 'Prenolol25mg', 'Prenolol50mg',\n",
        "    'Tanzaril50mg', 'Utmos15mg', 'Utmos30mg', 'XigduoXR10_1000mg', 'Zanidip10mg'\n",
        "]\n",
        "\n",
        "# Initialize lists to store results\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "# Initialize confusion matrix\n",
        "num_classes = len(text_labels)\n",
        "confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "# Function to get index of a label\n",
        "def get_label_index(label):\n",
        "    return text_labels.index(label)\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for image_filename in os.listdir(image_folder):\n",
        "    image_path = os.path.join(image_folder, image_filename)\n",
        "    if image_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "        # Open the image\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Prepare the inputs for the CLIP model\n",
        "        inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # Get the image-text similarity scores\n",
        "        logits_per_image = outputs.logits_per_image\n",
        "\n",
        "        # Compute the probabilities\n",
        "        probs = logits_per_image.softmax(dim=1).squeeze().tolist()\n",
        "\n",
        "        # Get the predicted label\n",
        "        predicted_index = np.argmax(probs)\n",
        "        predicted_label = text_labels[predicted_index]\n",
        "\n",
        "        # Extract true class from the image file name\n",
        "        true_label = os.path.splitext(image_filename)[0]\n",
        "\n",
        "        # Update confusion matrix\n",
        "        if true_label in text_labels:\n",
        "            true_index = get_label_index(true_label)\n",
        "            confusion_matrix[true_index, predicted_index] += 1\n",
        "\n",
        "        # Store results\n",
        "        predicted_labels.append(predicted_label)\n",
        "        true_labels.append(true_label)\n",
        "\n",
        "# Plotting the heatmap (confusion matrix)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=text_labels, yticklabels=text_labels)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uzp_ErQd0_nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Path to your local image folder\n",
        "image_folder_path = \"/content/drive/MyDrive/drug/CorpTest\"\n",
        "\n",
        "# Define multiple text labels for comparison\n",
        "text_labels = [\n",
        "    'Amlopine10mg', 'Amlopine5mg', 'Anapril5mg', 'Betalol10mg', 'Betalol40mg',\n",
        "    'Blopress16mg', 'Blopress8mg', 'BlopressPlus16mg', 'BlopressPlus8mg', 'Caduet10_10mg',\n",
        "    'Caduet5_10mg', 'Daonil5mg', 'DiamicronMR60mg', 'Diovan160mg', 'Diovan80mg',\n",
        "    'Forxiga10mg', 'Galvus50mg', 'GalvusMet50_1000mg', 'Gliclazide80mg', 'Gliparil2mg',\n",
        "    'Glucophage500mg', 'Glucophage850mg', 'GlucophageXR1000mg', 'GlucophageXR750mg', 'Glyxambi25_5mg',\n",
        "    'Janumet50_1000mg', 'Januvia100mg', 'Jardiance10mg', 'Jardiance25mg', 'JardianceDuo12.5_1000mg',\n",
        "    'Lanzaar100mg', 'Lercadip20mg', 'Madiplot10mg', 'Madiplot20mg', 'MetoprololStada100mg',\n",
        "    'Micardis40mg', 'MicardisPlus80_12.5mg', 'Minidiab5mg', 'Novonorm1mg', 'Novonorm2mg',\n",
        "    'Oseni25_15mg', 'Poli_uretic', 'Prenolol100mg', 'Prenolol25mg', 'Prenolol50mg',\n",
        "    'Tanzaril50mg', 'Utmos15mg', 'Utmos30mg', 'XigduoXR10_1000mg', 'Zanidip10mg'\n",
        "]\n",
        "\n",
        "# Initialize counters for correct and incorrect predictions\n",
        "correct_predictions = 0\n",
        "incorrect_predictions = 0\n",
        "\n",
        "# Loop through all image files in the folder\n",
        "for filename in os.listdir(image_folder_path):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Check for valid image files\n",
        "        # Get the correct class label from the filename (remove file extension)\n",
        "        correct_label = os.path.splitext(filename)[0]\n",
        "\n",
        "        image_path = os.path.join(image_folder_path, filename)\n",
        "\n",
        "        # Open the image\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Prepare the inputs for the CLIP model\n",
        "        inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # Get the image-text similarity scores\n",
        "        logits_per_image = outputs.logits_per_image\n",
        "\n",
        "        # Compute the probabilities\n",
        "        probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "        # Get the top 1 predicted label\n",
        "        top_prob, top_index = probs.topk(1, dim=1)\n",
        "        predicted_label = text_labels[top_index.item()]\n",
        "\n",
        "        # Compare the predicted label with the correct label\n",
        "        if predicted_label == correct_label:\n",
        "            correct_predictions += 1\n",
        "        else:\n",
        "            incorrect_predictions += 1\n",
        "            print(f\"Incorrect prediction for {filename}: Predicted {predicted_label} instead of {correct_label}\")\n",
        "\n",
        "# Print the total number of correct and incorrect predictions\n",
        "print(f\"\\nTotal correct predictions: {correct_predictions}\")\n",
        "print(f\"Total incorrect predictions: {incorrect_predictions}\")"
      ],
      "metadata": {
        "id": "gXerdUVPYv8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#image เทียบimage"
      ],
      "metadata": {
        "id": "F8i9mGcPEKcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from datetime import datetime\n",
        "\n",
        "# Check if GPU is available and use it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Path to the main directory containing 50 subfolders\n",
        "main_directory = \"/content/data 50 class add_augment\"\n",
        "\n",
        "# Prepare lists to store rows for CSV\n",
        "rows = []\n",
        "\n",
        "# Start timer for the whole process\n",
        "start_time = datetime.now()\n",
        "\n",
        "# Collect images and convert them to vectors\n",
        "for folder_name in os.listdir(main_directory):\n",
        "    folder_path = os.path.join(main_directory, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "\n",
        "        # Start timer for the current folder\n",
        "        folder_start_time = datetime.now()\n",
        "\n",
        "        # Collect all images from the current folder\n",
        "        image_files = [os.path.join(folder_path, image_name) for image_name in os.listdir(folder_path)]\n",
        "\n",
        "        for image_path in image_files:\n",
        "            # Open the image\n",
        "            image = Image.open(image_path)\n",
        "\n",
        "            # Prepare the inputs for the CLIP model\n",
        "            inputs = processor(text=[folder_name], images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "            # Move inputs to the GPU\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            # Forward pass through the model\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            # Get the image embedding\n",
        "            image_embedding = outputs.image_embeds.squeeze().cpu().tolist()\n",
        "\n",
        "            # Create a row for the CSV\n",
        "            row = [folder_name] + image_embedding\n",
        "            rows.append(row)\n",
        "\n",
        "        # End timer for the current folder\n",
        "        folder_end_time = datetime.now()\n",
        "        folder_duration = folder_end_time - folder_start_time\n",
        "        print(f\"Converted vectors for folder: {folder_name} in {folder_duration}\")\n",
        "\n",
        "# End timer for the whole process\n",
        "end_time = datetime.now()\n",
        "total_duration = end_time - start_time\n",
        "\n",
        "# Define the header for the CSV file\n",
        "header = ['TextLabel'] + [f'ImageEmbed_{i}' for i in range(len(image_embedding))]\n",
        "\n",
        "# Write the data to a CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/drug/FineTune/CLIPModel_new.csv'\n",
        "df = pd.DataFrame(rows, columns=header)\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Vectors have been successfully saved to: {csv_file_path}\")\n",
        "print(f\"Total time for processing all folders: {total_duration}\")"
      ],
      "metadata": {
        "id": "ZjhhRofVKHJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Load the CSV file containing the vectors\n",
        "csv_file_path = '/content/drive/MyDrive/drug/FineTune/CLIPModel_new.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract the text labels and image embeddings from the CSV\n",
        "text_labels = df['TextLabel'].tolist()\n",
        "image_embeddings = df[[col for col in df.columns if 'ImageEmbed_' in col]].values\n",
        "\n",
        "# Convert embeddings from lists to numpy arrays\n",
        "image_embeddings = np.array(image_embeddings)\n",
        "\n",
        "def compare_image_with_stored_vectors(new_image_path):\n",
        "    # Open the new image\n",
        "    image = Image.open(new_image_path)\n",
        "\n",
        "    # Prepare the inputs for the CLIP model\n",
        "    inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Forward pass through the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the image embedding for the new image\n",
        "    new_image_embedding = outputs.image_embeds.squeeze().cpu().numpy().reshape(1, -1)  # Ensure 2D array\n",
        "\n",
        "    # Compute cosine similarity between new image embedding and stored image embeddings\n",
        "    image_similarities = cosine_similarity(new_image_embedding, image_embeddings)\n",
        "\n",
        "    # Get index of the most similar class\n",
        "    most_similar_index = np.argmax(image_similarities, axis=1)[0]\n",
        "\n",
        "    # Return the predicted label\n",
        "    predicted_label = text_labels[most_similar_index]\n",
        "    return predicted_label\n",
        "\n",
        "# Process all images in the base folder\n",
        "base_folder = '/content/drive/MyDrive/drug/CorpTest'  # Base folder containing images\n",
        "\n",
        "# Initialize lists to store results\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "for image_file in os.listdir(base_folder):\n",
        "    image_path = os.path.join(base_folder, image_file)\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
        "        # Extract true class from the image file name (e.g., 'ClassName_1.jpg')\n",
        "        true_label = os.path.splitext(image_file)[0]\n",
        "\n",
        "        print(f\"\\nProcessing image: {image_path}\")\n",
        "        predicted_label = compare_image_with_stored_vectors(image_path)\n",
        "\n",
        "        predicted_labels.append(predicted_label)\n",
        "        true_labels.append(true_label)\n",
        "\n",
        "# Create a sorted list of unique class labels\n",
        "labels = sorted(set(true_labels + predicted_labels))  # All unique class labels, sorted alphabetically\n",
        "\n",
        "# Create a confusion matrix\n",
        "confusion_matrix = np.zeros((len(labels), len(labels)), dtype=int)\n",
        "\n",
        "for true, pred in zip(true_labels, predicted_labels):\n",
        "    true_index = labels.index(true)\n",
        "    pred_index = labels.index(pred)\n",
        "    confusion_matrix[true_index, pred_index] += 1\n",
        "\n",
        "# Create a heatmap from the confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1nsPQpJgPzxq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}